{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkqTsrVMa_5i",
        "outputId": "ebb2fbb5-ec93-46c2-acc7-57904c52076d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x780a10191710>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "# torch.use_deterministic_algorithms(True) # Needed for reproducible results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "21eguJ8Bb37j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_version = str(torch.__version__)\n",
        "print(f'torch version: {torch_version}')\n",
        "\n",
        "# scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "# sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "# %pip install torch-scatter -f $scatter_src\n",
        "# %pip install torch-sparse -f $sparse_src\n",
        "# %pip install torch-geometric\n",
        "# %pip install ogb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlxyW640fA7W",
        "outputId": "76310299-13ae-49ac-efcc-cf489ec91a18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your google drive in google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhVyxWShqpQR",
        "outputId": "2d3bd9cd-5264-42d4-9706-b771336d701a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USE_GPU = True\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif USE_GPU and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlgRisdQZDd0",
        "outputId": "ed624388-9c31-4bde-b0f1-9b2bea0c01ff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading"
      ],
      "metadata": {
        "id": "hYxNgpRsXQLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "spUV_AMKZF8a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/CS247/Project/ColdGAN/ml-1m/'\n",
        "USER_HEADERS_1M = [\"userId\", \"gender\", \"age\", \"occupation\", \"zipCode\"]\n",
        "RATING_HEADERS_1M = [\"userId\", \"movieId\", \"rating\", \"timestamp\"]\n",
        "df_user = pd.read_csv(data_path + \"users.dat\", sep=\"::\", header=None, names=USER_HEADERS_1M,\n",
        "            index_col=\"userId\", encoding='ISO-8859-1')\n",
        "\n",
        "df_ratings = pd.read_csv(data_path + \"ratings.dat\", sep=\"::\", header=None, names=RATING_HEADERS_1M,\n",
        "            index_col=\"userId\", encoding='ISO-8859-1').reset_index() # reset_index used to keep userId column\n",
        "\n",
        "df_rating_train, df_rating_test = train_test_split(df_ratings, test_size=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8auvf3PEWs3D",
        "outputId": "fe70981f-f08b-4e6a-aa72-91efbdad4d40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-711c360d1e83>:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  df_user = pd.read_csv(data_path + \"users.dat\", sep=\"::\", header=None, names=USER_HEADERS_1M,\n",
            "<ipython-input-7-711c360d1e83>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  df_ratings = pd.read_csv(data_path + \"ratings.dat\", sep=\"::\", header=None, names=RATING_HEADERS_1M,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_user[\"zipCode\"] = df_user[\"zipCode\"].astype(str)\n",
        "df_user[\"occupation\"] = df_user[\"occupation\"].astype(str)"
      ],
      "metadata": {
        "id": "H2gJ7J1MZ2Yy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "data_path = '/content/drive/MyDrive/CS247/Project/ColdGAN/ml-100k/'\n",
        "\n",
        "MOVIE_HEADERS = [\n",
        "    \"movieId\", \"title\", \"releaseDate\", \"videoReleaseDate\", \"IMDb URL\",\n",
        "    \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\",\n",
        "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
        "    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
        "]\n",
        "USER_HEADERS = [\"userId\", \"age\", \"gender\", \"occupation\", \"zipCode\"]\n",
        "RATING_HEADERS = [\"userId\", \"movieId\", \"rating\", \"timestamp\"]\n",
        "\n",
        "\n",
        "100K data\n",
        "# Process user data:\n",
        "df_user = pd.read_csv(\n",
        "    #Path to user data goes here\n",
        "    data_path + 'u.user',\n",
        "    sep='|',\n",
        "    header=None,\n",
        "    names=USER_HEADERS,\n",
        "    index_col='userId',\n",
        "    encoding='ISO-8859-1',\n",
        ")\n",
        "\n",
        "\n",
        "# Process rating data for training:\n",
        "df_rating_train = pd.read_csv(\n",
        "    data_path + 'u1.base',\n",
        "    sep='\\t',\n",
        "    header=None,\n",
        "    index_col='userId',\n",
        "    names=RATING_HEADERS,\n",
        ").reset_index()\n",
        "\n",
        "# Process rating data for testing:\n",
        "df_rating_test = pd.read_csv(\n",
        "    data_path + 'u1.test',\n",
        "    sep='\\t',\n",
        "    header=None,\n",
        "    index_col='userId',\n",
        "    names=RATING_HEADERS,\n",
        ").reset_index()\n",
        "\n",
        "\"\"\"\n",
        "#Combine user and rating data into one vector\n",
        "\n",
        "# df_train = df_user.copy().merge(df_rating_train, how='right', left_on='userId', right_on='userId')\n",
        "\n",
        "# df_test = df_user.copy().merge(df_rating_test, how='right', left_on='userId', right_on='userId')\n",
        "# rating = torch.from_numpy(df_rating_train['rating'].values).to(torch.long)\n"
      ],
      "metadata": {
        "id": "vNXXb2fFh8m-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "112fd520-ef78-40c3-a8a2-01dcab58461f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndata_path = \\'/content/drive/MyDrive/CS247/Project/ColdGAN/ml-100k/\\'\\n\\nMOVIE_HEADERS = [\\n    \"movieId\", \"title\", \"releaseDate\", \"videoReleaseDate\", \"IMDb URL\",\\n    \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\\'s\", \"Comedy\",\\n    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\\n    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\\n]\\nUSER_HEADERS = [\"userId\", \"age\", \"gender\", \"occupation\", \"zipCode\"]\\nRATING_HEADERS = [\"userId\", \"movieId\", \"rating\", \"timestamp\"]\\n\\n\\n100K data\\n# Process user data:\\ndf_user = pd.read_csv(\\n    #Path to user data goes here\\n    data_path + \\'u.user\\',\\n    sep=\\'|\\',\\n    header=None,\\n    names=USER_HEADERS,\\n    index_col=\\'userId\\',\\n    encoding=\\'ISO-8859-1\\',\\n)\\n\\n\\n# Process rating data for training:\\ndf_rating_train = pd.read_csv(\\n    data_path + \\'u1.base\\',\\n    sep=\\'\\t\\',\\n    header=None,\\n    index_col=\\'userId\\',\\n    names=RATING_HEADERS,\\n).reset_index()\\n\\n# Process rating data for testing:\\ndf_rating_test = pd.read_csv(\\n    data_path + \\'u1.test\\',\\n    sep=\\'\\t\\',\\n    header=None,\\n    index_col=\\'userId\\',\\n    names=RATING_HEADERS,\\n).reset_index()\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_mapping = {idx: i for i, idx in enumerate(df_user.index)}\n",
        "\n",
        "age = df_user['age'].values / df_user['age'].values.max()\n",
        "age = torch.from_numpy(age).to(torch.float).view(-1, 1)\n",
        "\n",
        "gender = df_user['gender'].str.get_dummies().values\n",
        "gender = torch.from_numpy(gender).to(torch.float)\n",
        "\n",
        "occupation = df_user['occupation'].str.get_dummies().values\n",
        "occupation = torch.from_numpy(occupation).to(torch.float)\n",
        "\n",
        "zipcode = df_user['zipCode'].str.get_dummies().values\n",
        "zipcode = torch.from_numpy(zipcode).to(torch.float)\n",
        "\n",
        "users = torch.cat([age, gender, occupation, zipcode], dim=-1).to(device)"
      ],
      "metadata": {
        "id": "Ua178u7vmUYP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = []\n",
        "timestamps = []\n",
        "num_movies = 3953 # from ml-1M README\n",
        "for user in user_mapping:\n",
        "  user_ratings_df = df_rating_train.loc[df_rating_train['userId'] == user].sort_values('timestamp')\n",
        "  user_ratings = torch.zeros((num_movies,), dtype=torch.float)\n",
        "  user_timestamps = torch.zeros((num_movies,), dtype=torch.float)\n",
        "  for i, (index, row) in enumerate(user_ratings_df.iterrows()):\n",
        "    user_ratings[row['movieId']-1] = row['rating']\n",
        "    user_timestamps[row['movieId']-1] = i + 1\n",
        "\n",
        "\n",
        "  ratings.append(user_ratings)\n",
        "  timestamps.append(user_timestamps)\n",
        "\n",
        "ratings = torch.from_numpy(np.array(ratings)).to(device)\n",
        "timestamps = torch.from_numpy(np.array(timestamps))"
      ],
      "metadata": {
        "id": "ZY2xRMB4mwAB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_popularity = df_rating_train['movieId'].value_counts().sort_index()\n",
        "movie_popularity = movie_popularity.reindex(list(range(1,num_movies+1)),fill_value=0).values\n",
        "movie_popularity = torch.from_numpy(movie_popularity / np.max(movie_popularity)).to(device)"
      ],
      "metadata": {
        "id": "xOWqyWND6R9c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(movie_popularity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-fi_3YM7SqB",
        "outputId": "0ee3b8af-6cdb-4808-8e95-66744a8cf720"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6211, 0.2045, 0.1390,  ..., 0.0113, 0.1138, 0.0000], device='cuda:0',\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ratings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoOkDevmoL3y",
        "outputId": "644fe74f-0eaf-45c6-ea77-46e3fbda83ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(users))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWELFj8moN0s",
        "outputId": "04a21e00-cb1f-4f99-ed00-99daa5746712"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(movie_popularity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y-f4qp_6Zdb",
        "outputId": "132aebef-ae12-4656-83ef-d8efca01563f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3953"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class RatingsDataset(Dataset):\n",
        "    def __init__(self, users, ratings, timestamps):\n",
        "        self.len = len(users)\n",
        "        self.users = users\n",
        "        self.ratings = ratings\n",
        "        self.timestamps = timestamps\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user_vec = self.users[idx]\n",
        "        ratings_vec = self.ratings[idx]\n",
        "        timestamps_vec = self.timestamps[idx]\n",
        "\n",
        "        return user_vec, ratings_vec, timestamps_vec\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn(data):\n",
        "        user_vec = torch.stack([_[0] for _ in data], dim=0)\n",
        "        ratings_vec = torch.stack([_[1] for _ in data], dim=0)\n",
        "        timestamps_vec = torch.stack([_[2] for _ in data], dim=0)\n",
        "        return user_vec, ratings_vec, timestamps_vec"
      ],
      "metadata": {
        "id": "MZo4xrJ4cNUA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 41\n",
        "dataset = RatingsDataset(users, ratings, timestamps)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=RatingsDataset.collate_fn)"
      ],
      "metadata": {
        "id": "KAS3-dbu1gRu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 41\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 3\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 100\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparameter for Adam optimizers\n",
        "beta1 = 0.5\n"
      ],
      "metadata": {
        "id": "je3_b7cUojqx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get batch data from training set\n",
        "def get_batch_data(file, index, size):  # 1,5->1,2,3,4,5\n",
        "    user = []\n",
        "    item = []\n",
        "    label = []\n",
        "    for i in range(index, index + size):\n",
        "        line = linecache.getline(file, i)\n",
        "        line = line.strip()\n",
        "        line = line.split()\n",
        "        user.append(int(line[0]))\n",
        "        user.append(int(line[0]))\n",
        "        item.append(int(line[1]))\n",
        "        item.append(int(line[2]))\n",
        "        label.append(1.)\n",
        "        label.append(0.)\n",
        "    return user, item, label\n",
        "\n",
        "def file_len(fname):\n",
        "    with open(fname) as f:\n",
        "        for i, l in enumerate(f):\n",
        "            pass\n",
        "    return i + 1\n",
        "\n",
        "\n",
        "# Get category of items\n",
        "def get_category(file_in):\n",
        "    category = {}\n",
        "    #with open(file_in) as fin:\n",
        "    with open(file_in,encoding='unicode_escape') as fin:\n",
        "        for line in fin:\n",
        "            line = line.split('|')\n",
        "            iid = int(line[0]) - 1  # item id starts from 0\n",
        "            category[iid] = line[6:24]\n",
        "    return category\n",
        "\n",
        "\n",
        "# Get training/testing data\n",
        "def get_train_test_data(file_in):\n",
        "    # only record user-item pairs with rating >=4\n",
        "    user_item = {}\n",
        "    with open(file_in) as fin:\n",
        "        for line in fin:\n",
        "            line = line.split()\n",
        "            uid = int(line[0])\n",
        "            iid = int(line[1])\n",
        "            r = float(line[2])\n",
        "            if uid in user_item:\n",
        "                user_item[uid].append(iid)\n",
        "            else:\n",
        "                user_item[uid] = [iid]\n",
        "    return user_item\n",
        "\n",
        "\n",
        "def precision_at_k(r, k):\n",
        "    \"\"\"Score is precision @ k\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "    Returns:\n",
        "        Precision @ k\n",
        "    Raises:\n",
        "        ValueError: len(r) must be >= k\n",
        "    \"\"\"\n",
        "    assert k >= 1\n",
        "    r = np.asarray(r)[:k]\n",
        "    return np.mean(r)\n",
        "\n",
        "\n",
        "def average_precision(r):\n",
        "    \"\"\"Score is average precision (area under PR curve)\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "    Returns:\n",
        "        Average precision\n",
        "    \"\"\"\n",
        "    r = np.asarray(r)\n",
        "    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
        "    if not out:\n",
        "        return 0.\n",
        "    return np.mean(out)\n",
        "\n",
        "\n",
        "def mean_average_precision(rs):\n",
        "    \"\"\"Score is mean average precision\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "    Returns:\n",
        "        Mean average precision\n",
        "    \"\"\"\n",
        "    return np.mean([average_precision(r) for r in rs])\n",
        "\n",
        "\n",
        "def dcg_at_k(r, k):\n",
        "    \"\"\"Score is discounted cumulative gain (dcg)\n",
        "    Relevance is positive real values.  Can use binary\n",
        "    as the previous methods.\n",
        "    Returns:\n",
        "        Discounted cumulative gain\n",
        "    \"\"\"\n",
        "    r = np.asfarray(r)[:k]\n",
        "    if r.size:\n",
        "        # if method == 0:\n",
        "        #     return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
        "        # elif method == 1:\n",
        "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
        "        # else:\n",
        "        #     raise ValueError('method must be 0 or 1.')\n",
        "    else:\n",
        "        return 0.\n",
        "\n",
        "\n",
        "def ndcg_at_k(r, k):\n",
        "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
        "    Relevance is positive real values.  Can use binary\n",
        "    as the previous methods.\n",
        "    Returns:\n",
        "        Normalized discounted cumulative gain\n",
        "    \"\"\"\n",
        "    dcg_max = dcg_at_k(sorted(r, reverse=True), k)\n",
        "    if not dcg_max:\n",
        "        return 0.\n",
        "    return dcg_at_k(r, k) / dcg_max\n",
        "\n",
        "\n",
        "def recall_at_k(r, k, all_pos_num):\n",
        "    r = np.asfarray(r)[:k]\n",
        "    return np.sum(r) / all_pos_num\n",
        "\n",
        "\n",
        "def F1(pre, rec):\n",
        "    if pre + rec > 0:\n",
        "        return (2.0 * pre * rec) / (pre + rec)\n",
        "    else:\n",
        "        return 0.\n",
        "\n",
        "\n",
        "def diversity_by_category(selected_items, item_cate, cate_num):\n",
        "    cate = []\n",
        "    for iid in selected_items:\n",
        "        try:\n",
        "            cate.append(item_cate[iid])\n",
        "        except KeyError:\n",
        "            pass\n",
        "\n",
        "    cate_count = np.count_nonzero(np.sum(np.asarray(cate, np.float32), axis=0))\n",
        "\n",
        "    return cate_count/cate_num\n",
        "\n",
        "\n",
        "def get_div_train_data(file_in):\n",
        "    user_train_samples = {}\n",
        "\n",
        "    with open(file_in) as fin:\n",
        "        for line in fin:\n",
        "            line = line.split('\\t')\n",
        "            uid = int(line[0])\n",
        "            items = list(map(int, line[1:]))\n",
        "            if uid in user_train_samples:\n",
        "                user_train_samples[uid].append(items)\n",
        "            else:\n",
        "                user_train_samples[uid] = [items]\n",
        "\n",
        "    return user_train_samples\n",
        "\n",
        "\n",
        "def generate_pairwise_diversity_training_data(file_train, file_cate, file_out_pos, file_out_neg, user_num):\n",
        "    pos_data = []  # data for output\n",
        "    neg_data = []\n",
        "\n",
        "    #########################################################################################\n",
        "    # Load data\n",
        "    #########################################################################################\n",
        "    category = get_category(file_cate)\n",
        "    user_item = get_train_test_data(file_train)\n",
        "\n",
        "    # for each user, generate diversity set\n",
        "    for i in range(0, user_num):\n",
        "        uid = i;\n",
        "        print('user:', uid)\n",
        "        try:\n",
        "            items = user_item[uid]\n",
        "        except KeyError:\n",
        "            pass\n",
        "        # the number of trials for each user is set to be the number of viewed items\n",
        "        for j in range(0, len(items)):\n",
        "            first_item = items[j]\n",
        "            pos_div_set = [first_item]  # make sure each viewed item is sampled\n",
        "            pos_cate = [category[first_item]]\n",
        "            num_cate = np.count_nonzero(np.sum(np.asarray(pos_cate, np.float32), axis=0))\n",
        "            # the number of trials for each diversity set is the number of viewed items\n",
        "            for k in range(0, len(items)):\n",
        "                new_item = np.random.choice(items)\n",
        "                try:\n",
        "                    pos_cate.append(category[new_item])\n",
        "                    new_num_cate = np.count_nonzero(np.sum(np.asarray(pos_cate, np.float32), axis=0))\n",
        "                    if new_num_cate - num_cate > 0:\n",
        "                        pos_div_set.append(new_item)\n",
        "                        num_cate = new_num_cate\n",
        "                    if len(pos_div_set) == 10:\n",
        "                        break;\n",
        "                except KeyError:\n",
        "                    pass\n",
        "\n",
        "            pos_div_set.sort()\n",
        "            pos_data.append(str(uid) + '\\t' + '\\t'.join(str(x) for x in pos_div_set))\n",
        "\n",
        "            neg_div_set = [first_item]  # make sure each viewed item is sampled\n",
        "            neg_cate = np.asarray(category[first_item], np.int32).nonzero()[0]\n",
        "            # the number of trials for each diversity set is the number of viewed items\n",
        "            for k in range(0, len(items)):\n",
        "                new_item = items[k]\n",
        "                try:\n",
        "                    if new_item not in neg_div_set:\n",
        "                        new_cate = np.asarray(category[new_item], np.int32).nonzero()[0]\n",
        "                        if np.array_equal(neg_cate, new_cate):\n",
        "                            neg_div_set = np.append(neg_div_set, new_item)\n",
        "                            if len(neg_div_set) > 10:  # due to tensorflow bug\n",
        "                                neg_div_set = np.random.choice(neg_div_set, 10, replace=False)\n",
        "                except KeyError:\n",
        "                    pass\n",
        "            neg_div_set.sort()\n",
        "            neg_data.append(str(uid) + '\\t' + '\\t'.join(str(x) for x in neg_div_set))\n",
        "\n",
        "    with open(file_out_pos, 'w')as fout:\n",
        "        fout.write('\\n'.join(pos_data))\n",
        "\n",
        "    with open(file_out_neg, 'w')as fout:\n",
        "        fout.write('\\n'.join(neg_data))\n"
      ],
      "metadata": {
        "id": "0PD0ahrZopKR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom weights initialization called on ``netG`` and ``netD``\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "PsYRXUjlorFy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generator"
      ],
      "metadata": {
        "id": "_AjYbVbWnDak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Code\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [nn.Linear(in_feat, out_feat)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm1d(out_feat))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            *block(num_movies, 128, normalize=False),\n",
        "            *block(128, 256),\n",
        "            nn.Dropout(p=0.25),\n",
        "            *block(256, 512),\n",
        "            nn.Dropout(p=0.25),\n",
        "            *block(512, 1024),\n",
        "            nn.Dropout(p=0.25),\n",
        "            *block(1024, 2048),\n",
        "            nn.Dropout(p=0.25),\n",
        "            nn.Linear(2048, num_movies),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, user_vec, rating_vec):\n",
        "        return self.main(rating_vec)"
      ],
      "metadata": {
        "id": "-9mEA4iXoryi"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngpu = 1"
      ],
      "metadata": {
        "id": "6C83GYP-2ZdQ"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the generator\n",
        "netG = Generator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-GPU if desired\n",
        "# if (device == 'cuda') and (ngpu > 1):\n",
        "#     netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "# # Apply the ``weights_init`` function to randomly initialize all weights\n",
        "# #  to ``mean=0``, ``stdev=0.02``.\n",
        "# netG.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(netG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA5kYr0zot3o",
        "outputId": "5f44e3c1-c6be-4f41-fcae-a1fff611f8ec"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): Linear(in_features=3953, out_features=128, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.25, inplace=False)\n",
            "    (6): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): Dropout(p=0.25, inplace=False)\n",
            "    (10): Linear(in_features=512, out_features=1024, bias=True)\n",
            "    (11): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Dropout(p=0.25, inplace=False)\n",
            "    (14): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "    (15): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Dropout(p=0.25, inplace=False)\n",
            "    (18): Linear(in_features=2048, out_features=3953, bias=True)\n",
            "    (19): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## discriminator"
      ],
      "metadata": {
        "id": "IPBZ95uiPEdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(num_movies, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.25),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.25),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.25),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, user_vec, rating_vec):\n",
        "        return self.main(rating_vec)"
      ],
      "metadata": {
        "id": "WxnF5N83oxuz"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Discriminator\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-GPU if desired\n",
        "# if (device == 'cuda') and (ngpu > 1):\n",
        "#     netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "# # Apply the ``weights_init`` function to randomly initialize all weights\n",
        "# # like this: ``to mean=0, stdev=0.2``.\n",
        "# netD.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(netD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p840enYfozSE",
        "outputId": "e4bf3064-4f96-4a11-e680-b94f7379d22b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Linear(in_features=3953, out_features=1024, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.25, inplace=False)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.25, inplace=False)\n",
            "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Dropout(p=0.25, inplace=False)\n",
            "    (9): Linear(in_features=256, out_features=1, bias=True)\n",
            "    (10): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the ``BCELoss`` function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "# fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "iz7Lxq5Io2K6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate cold state from warm state\n",
        "p_min = 0.0\n",
        "p_max = 0.85\n",
        "alpha = 1\n",
        "def rejuvenation_function(rating_vector, timestamp_vector, alpha):\n",
        "  #Need time + popularity of item rating\n",
        "  #For tth item, probability of choosing in cold state is\n",
        "  #pm(t) = p_min + (p_max - p_min) * exp(-alpha * [t - pop(i_t)]/ [count(wm)])\n",
        "  count = torch.count_nonzero(rating_vector)\n",
        "  t_vector = timestamp_vector.to(device)\n",
        "  # cpu index is -1\n",
        "  prob_vector = p_min + (p_max - p_min) * torch.exp(-alpha * (t_vector - movie_popularity)/ count)\n",
        "  random_selection = torch.from_numpy(np.random.rand(num_movies)).to(device) < prob_vector\n",
        "  return rating_vector * random_selection"
      ],
      "metadata": {
        "id": "VqZ5I56ko-RF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warm_vector = ratings[0]\n",
        "cold_vector = rejuvenation_function(ratings[0], timestamps[0], alpha)\n",
        "for i in range(num_movies):\n",
        "  if warm_vector[i] != cold_vector[i]:\n",
        "    print(warm_vector[i])\n",
        "    print(cold_vector[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De4TElkjKXK9",
        "outputId": "0c850b4a-df13-48f0-87fa-08f5d4d193ec"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(5., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(4., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(4., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(5., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(3., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(4., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(4., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(4., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(5., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(4., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(4., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(4., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(4., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(4., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(5., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(3., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(4., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(5., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n",
            "tensor(4., device='cuda:0')\n",
            "tensor(0., device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## relevant loss"
      ],
      "metadata": {
        "id": "ESJXeXRlmQLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relevant_loss(rating_vector, actual_warm):\n",
        "  #Sum of binary cross-entropy loss b/w sigmoid gan out and wrel\n",
        "  #divided by number items rated by user\n",
        "  # equation 8 in ColdGAN paper\n",
        "  n_m = torch.count_nonzero(actual_warm, axis=1).view(-1, 1).to(device)\n",
        "  avg_rating = torch.mean(actual_warm, axis=1).view(-1, 1).to(device)\n",
        "  relevance_vector = (actual_warm > avg_rating).float()\n",
        "  activation_vector = (actual_warm > 0).float()\n",
        "\n",
        "  bce_loss = torch.nn.functional.binary_cross_entropy(\n",
        "      torch.nn.functional.sigmoid(rating_vector), relevance_vector, reduction='none')\n",
        "  loss = torch.sum(bce_loss * activation_vector) / n_m\n",
        "\n",
        "  return loss\n"
      ],
      "metadata": {
        "id": "D5Mh9XYhrtcX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class RelevantLoss(nn.Module):\n",
        "  def init(self):\n",
        "    super(RelevantLoss, self).init()\n",
        "\n",
        "  def forward(self, rating_vector, actual_warm):\n",
        "    #Sum of binary cross-entropy loss b/w sigmoid gan out and wrel\n",
        "    #divided by number items rated by user\n",
        "    n_m = torch.count_nonzero(actual_warm, axis=1).view(-1, 1)\n",
        "    avg_rating = torch.mean(actual_warm, axis=1).view(-1, 1)\n",
        "    relevance_vector = (actual_warm > avg_rating).float()\n",
        "    activation_vector = (actual_warm > 0).float()\n",
        "    bce_loss = torch.sum(F.binary_cross_entropy(F.sigmoid(rating_vector) * activation_vector, relevance_vector * activation_vector)  / n_m)\n",
        "\n",
        "    return bce_loss\n",
        "rel_loss = RelevantLoss()"
      ],
      "metadata": {
        "id": "YZExBvdVmiHp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataloader:\n",
        "  cold = rejuvenation_function(i[1], i[2], alpha)\n",
        "  print(relevant_loss(cold, i[1]).sum())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgI1TGqpUmwU",
        "outputId": "5b593b30-1c7b-44a2-d129-e4656592d800"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(613.4436, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.use_deterministic_algorithms(False)"
      ],
      "metadata": {
        "id": "dkNa6gz1gsnz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training loop"
      ],
      "metadata": {
        "id": "tz3mLisAmWMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "\n",
        "# Lists to keep track of progress\n",
        "fake_warm = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "print(dataloader)\n",
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # For each batch in the dataloader\n",
        "    for i, data in enumerate(dataloader):\n",
        "        user_vecs = data[0]\n",
        "        ratings_vecs = data[1]\n",
        "        timestamps_vecs = data[2]\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Train with all-real batch\n",
        "        netD.zero_grad()\n",
        "        # Format batch\n",
        "        b_size = user_vecs.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "        # Forward pass real batch through D\n",
        "        output = netD(user_vecs, ratings_vecs).view(-1)\n",
        "        # Calculate loss on all-real batch\n",
        "        errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "        cold_vectors = rejuvenation_function(ratings_vecs, timestamps_vecs, alpha)\n",
        "        # Generate fake image batch with G\n",
        "        fake  = netG(user_vecs, cold_vectors)\n",
        "        label.fill_(fake_label)\n",
        "        # Classify all fake batch with D\n",
        "        output = netD(user_vecs, fake).view(-1)\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output, label)\n",
        "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Compute error of D as sum over the fake and the real batches\n",
        "        errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        #Generate fakes again\n",
        "        fake  = netG(user_vecs, cold_vectors)\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        output = netD(user_vecs, fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        # rel_loss = 0#relevant_loss(fake, ratings_vecs).sum() / np.count_nonzero(ratings_vecs)\n",
        "        errG_D = criterion(output, label)\n",
        "        errG_R = rel_loss(fake, ratings_vecs)\n",
        "        # Calculate gradients for G\n",
        "        errG_D.backward(retain_graph=True)\n",
        "        errG_R.backward()\n",
        "        errG = errG_D + errG_R\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "            #Get random cold vector\n",
        "            idx = np.random.randint(len(users), size=2)\n",
        "            noise_user = users[idx]\n",
        "            fixed_noise = rejuvenation_function(ratings[idx], timestamps[idx], alpha=0.1)\n",
        "            with torch.no_grad():\n",
        "                fake = netG(noise_user, fixed_noise)\n",
        "            fake_warm.append((fake, idx))\n",
        "\n",
        "        iters += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIyQkGLBmpJY",
        "outputId": "cc937899-87bf-4b21-d2e3-a8998f900cd6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training Loop...\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7809170d78b0>\n",
            "[0/100][0/148]\tLoss_D: 1.3827\tLoss_G: 0.6755\tD(x): 0.5213\tD(G(z)): 0.5186 / 0.5180\n",
            "[0/100][50/148]\tLoss_D: 1.3882\tLoss_G: 0.6703\tD(x): 0.5179\tD(G(z)): 0.5182 / 0.5183\n",
            "[0/100][100/148]\tLoss_D: 1.3863\tLoss_G: 0.6706\tD(x): 0.5194\tD(G(z)): 0.5186 / 0.5189\n",
            "[1/100][0/148]\tLoss_D: 1.3849\tLoss_G: 0.6671\tD(x): 0.5198\tD(G(z)): 0.5184 / 0.5198\n",
            "[1/100][50/148]\tLoss_D: 1.3904\tLoss_G: 0.6733\tD(x): 0.5179\tD(G(z)): 0.5192 / 0.5189\n",
            "[1/100][100/148]\tLoss_D: 1.3898\tLoss_G: 0.6724\tD(x): 0.5188\tD(G(z)): 0.5197 / 0.5185\n",
            "[2/100][0/148]\tLoss_D: 1.3857\tLoss_G: 0.6700\tD(x): 0.5187\tD(G(z)): 0.5177 / 0.5180\n",
            "[2/100][50/148]\tLoss_D: 1.3837\tLoss_G: 0.6711\tD(x): 0.5208\tD(G(z)): 0.5187 / 0.5183\n",
            "[2/100][100/148]\tLoss_D: 1.3894\tLoss_G: 0.6716\tD(x): 0.5180\tD(G(z)): 0.5188 / 0.5173\n",
            "[3/100][0/148]\tLoss_D: 1.3872\tLoss_G: 0.6683\tD(x): 0.5202\tD(G(z)): 0.5197 / 0.5185\n",
            "[3/100][50/148]\tLoss_D: 1.3862\tLoss_G: 0.6705\tD(x): 0.5183\tD(G(z)): 0.5175 / 0.5177\n",
            "[3/100][100/148]\tLoss_D: 1.3862\tLoss_G: 0.6714\tD(x): 0.5186\tD(G(z)): 0.5178 / 0.5179\n",
            "[4/100][0/148]\tLoss_D: 1.3835\tLoss_G: 0.6734\tD(x): 0.5205\tD(G(z)): 0.5183 / 0.5187\n",
            "[4/100][50/148]\tLoss_D: 1.3833\tLoss_G: 0.6742\tD(x): 0.5203\tD(G(z)): 0.5180 / 0.5185\n",
            "[4/100][100/148]\tLoss_D: 1.3877\tLoss_G: 0.6687\tD(x): 0.5191\tD(G(z)): 0.5191 / 0.5187\n",
            "[5/100][0/148]\tLoss_D: 1.3854\tLoss_G: 0.6738\tD(x): 0.5201\tD(G(z)): 0.5188 / 0.5182\n",
            "[5/100][50/148]\tLoss_D: 1.3887\tLoss_G: 0.6752\tD(x): 0.5186\tD(G(z)): 0.5190 / 0.5190\n",
            "[5/100][100/148]\tLoss_D: 1.3881\tLoss_G: 0.6734\tD(x): 0.5187\tD(G(z)): 0.5188 / 0.5176\n",
            "[6/100][0/148]\tLoss_D: 1.3889\tLoss_G: 0.6711\tD(x): 0.5185\tD(G(z)): 0.5191 / 0.5187\n",
            "[6/100][50/148]\tLoss_D: 1.3844\tLoss_G: 0.6737\tD(x): 0.5202\tD(G(z)): 0.5185 / 0.5183\n",
            "[6/100][100/148]\tLoss_D: 1.3866\tLoss_G: 0.6795\tD(x): 0.5188\tD(G(z)): 0.5182 / 0.5180\n",
            "[7/100][0/148]\tLoss_D: 1.3826\tLoss_G: 0.6744\tD(x): 0.5211\tD(G(z)): 0.5184 / 0.5189\n",
            "[7/100][50/148]\tLoss_D: 1.3850\tLoss_G: 0.6730\tD(x): 0.5208\tD(G(z)): 0.5193 / 0.5189\n",
            "[7/100][100/148]\tLoss_D: 1.3896\tLoss_G: 0.6730\tD(x): 0.5174\tD(G(z)): 0.5183 / 0.5180\n",
            "[8/100][0/148]\tLoss_D: 1.3915\tLoss_G: 0.6743\tD(x): 0.5159\tD(G(z)): 0.5178 / 0.5181\n",
            "[8/100][50/148]\tLoss_D: 1.3846\tLoss_G: 0.6723\tD(x): 0.5194\tD(G(z)): 0.5178 / 0.5180\n",
            "[8/100][100/148]\tLoss_D: 1.3905\tLoss_G: 0.6688\tD(x): 0.5168\tD(G(z)): 0.5182 / 0.5182\n",
            "[9/100][0/148]\tLoss_D: 1.3867\tLoss_G: 0.6717\tD(x): 0.5190\tD(G(z)): 0.5185 / 0.5184\n",
            "[9/100][50/148]\tLoss_D: 1.3847\tLoss_G: 0.6749\tD(x): 0.5194\tD(G(z)): 0.5179 / 0.5177\n",
            "[9/100][100/148]\tLoss_D: 1.3816\tLoss_G: 0.6766\tD(x): 0.5216\tD(G(z)): 0.5184 / 0.5183\n",
            "[10/100][0/148]\tLoss_D: 1.3788\tLoss_G: 0.6771\tD(x): 0.5236\tD(G(z)): 0.5188 / 0.5177\n",
            "[10/100][50/148]\tLoss_D: 1.3896\tLoss_G: 0.6716\tD(x): 0.5179\tD(G(z)): 0.5188 / 0.5191\n",
            "[10/100][100/148]\tLoss_D: 1.3837\tLoss_G: 0.6722\tD(x): 0.5197\tD(G(z)): 0.5176 / 0.5186\n",
            "[11/100][0/148]\tLoss_D: 1.3921\tLoss_G: 0.6743\tD(x): 0.5166\tD(G(z)): 0.5188 / 0.5189\n",
            "[11/100][50/148]\tLoss_D: 1.3909\tLoss_G: 0.6687\tD(x): 0.5166\tD(G(z)): 0.5182 / 0.5188\n",
            "[11/100][100/148]\tLoss_D: 1.3879\tLoss_G: 0.6689\tD(x): 0.5188\tD(G(z)): 0.5187 / 0.5190\n",
            "[12/100][0/148]\tLoss_D: 1.3888\tLoss_G: 0.6703\tD(x): 0.5179\tD(G(z)): 0.5185 / 0.5185\n",
            "[12/100][50/148]\tLoss_D: 1.3902\tLoss_G: 0.6775\tD(x): 0.5170\tD(G(z)): 0.5182 / 0.5184\n",
            "[12/100][100/148]\tLoss_D: 1.3896\tLoss_G: 0.6716\tD(x): 0.5174\tD(G(z)): 0.5183 / 0.5190\n",
            "[13/100][0/148]\tLoss_D: 1.3855\tLoss_G: 0.6711\tD(x): 0.5193\tD(G(z)): 0.5181 / 0.5190\n",
            "[13/100][50/148]\tLoss_D: 1.3844\tLoss_G: 0.6778\tD(x): 0.5207\tD(G(z)): 0.5189 / 0.5172\n",
            "[13/100][100/148]\tLoss_D: 1.3925\tLoss_G: 0.6729\tD(x): 0.5167\tD(G(z)): 0.5190 / 0.5190\n",
            "[14/100][0/148]\tLoss_D: 1.3857\tLoss_G: 0.6734\tD(x): 0.5189\tD(G(z)): 0.5179 / 0.5173\n",
            "[14/100][50/148]\tLoss_D: 1.3905\tLoss_G: 0.6725\tD(x): 0.5173\tD(G(z)): 0.5187 / 0.5186\n",
            "[14/100][100/148]\tLoss_D: 1.3849\tLoss_G: 0.6727\tD(x): 0.5201\tD(G(z)): 0.5186 / 0.5183\n",
            "[15/100][0/148]\tLoss_D: 1.3881\tLoss_G: 0.6713\tD(x): 0.5184\tD(G(z)): 0.5186 / 0.5185\n",
            "[15/100][50/148]\tLoss_D: 1.3829\tLoss_G: 0.6761\tD(x): 0.5201\tD(G(z)): 0.5176 / 0.5181\n",
            "[15/100][100/148]\tLoss_D: 1.3843\tLoss_G: 0.6738\tD(x): 0.5194\tD(G(z)): 0.5176 / 0.5181\n",
            "[16/100][0/148]\tLoss_D: 1.3845\tLoss_G: 0.6710\tD(x): 0.5197\tD(G(z)): 0.5180 / 0.5187\n",
            "[16/100][50/148]\tLoss_D: 1.3836\tLoss_G: 0.6753\tD(x): 0.5196\tD(G(z)): 0.5175 / 0.5192\n",
            "[16/100][100/148]\tLoss_D: 1.3803\tLoss_G: 0.6716\tD(x): 0.5218\tD(G(z)): 0.5180 / 0.5177\n",
            "[17/100][0/148]\tLoss_D: 1.3804\tLoss_G: 0.6730\tD(x): 0.5216\tD(G(z)): 0.5178 / 0.5182\n",
            "[17/100][50/148]\tLoss_D: 1.3856\tLoss_G: 0.6743\tD(x): 0.5195\tD(G(z)): 0.5184 / 0.5178\n",
            "[17/100][100/148]\tLoss_D: 1.3864\tLoss_G: 0.6694\tD(x): 0.5199\tD(G(z)): 0.5191 / 0.5190\n",
            "[18/100][0/148]\tLoss_D: 1.3833\tLoss_G: 0.6755\tD(x): 0.5206\tD(G(z)): 0.5183 / 0.5182\n",
            "[18/100][50/148]\tLoss_D: 1.3860\tLoss_G: 0.6765\tD(x): 0.5197\tD(G(z)): 0.5188 / 0.5165\n",
            "[18/100][100/148]\tLoss_D: 1.3891\tLoss_G: 0.6726\tD(x): 0.5173\tD(G(z)): 0.5180 / 0.5174\n",
            "[19/100][0/148]\tLoss_D: 1.3881\tLoss_G: 0.6740\tD(x): 0.5179\tD(G(z)): 0.5181 / 0.5184\n",
            "[19/100][50/148]\tLoss_D: 1.3859\tLoss_G: 0.6757\tD(x): 0.5208\tD(G(z)): 0.5196 / 0.5182\n",
            "[19/100][100/148]\tLoss_D: 1.3859\tLoss_G: 0.6725\tD(x): 0.5189\tD(G(z)): 0.5179 / 0.5169\n",
            "[20/100][0/148]\tLoss_D: 1.3834\tLoss_G: 0.6753\tD(x): 0.5204\tD(G(z)): 0.5182 / 0.5184\n",
            "[20/100][50/148]\tLoss_D: 1.3856\tLoss_G: 0.6730\tD(x): 0.5195\tD(G(z)): 0.5183 / 0.5180\n",
            "[20/100][100/148]\tLoss_D: 1.3903\tLoss_G: 0.6722\tD(x): 0.5182\tD(G(z)): 0.5194 / 0.5180\n",
            "[21/100][0/148]\tLoss_D: 1.3856\tLoss_G: 0.6726\tD(x): 0.5199\tD(G(z)): 0.5187 / 0.5187\n",
            "[21/100][50/148]\tLoss_D: 1.3875\tLoss_G: 0.6719\tD(x): 0.5185\tD(G(z)): 0.5184 / 0.5188\n",
            "[21/100][100/148]\tLoss_D: 1.3879\tLoss_G: 0.6700\tD(x): 0.5176\tD(G(z)): 0.5177 / 0.5185\n",
            "[22/100][0/148]\tLoss_D: 1.3863\tLoss_G: 0.6705\tD(x): 0.5201\tD(G(z)): 0.5193 / 0.5183\n",
            "[22/100][50/148]\tLoss_D: 1.3841\tLoss_G: 0.6774\tD(x): 0.5214\tD(G(z)): 0.5194 / 0.5178\n",
            "[22/100][100/148]\tLoss_D: 1.3905\tLoss_G: 0.6766\tD(x): 0.5179\tD(G(z)): 0.5192 / 0.5175\n",
            "[23/100][0/148]\tLoss_D: 1.3875\tLoss_G: 0.6719\tD(x): 0.5185\tD(G(z)): 0.5183 / 0.5185\n",
            "[23/100][50/148]\tLoss_D: 1.3872\tLoss_G: 0.6720\tD(x): 0.5192\tD(G(z)): 0.5188 / 0.5185\n",
            "[23/100][100/148]\tLoss_D: 1.3885\tLoss_G: 0.6709\tD(x): 0.5189\tD(G(z)): 0.5192 / 0.5183\n",
            "[24/100][0/148]\tLoss_D: 1.3833\tLoss_G: 0.6716\tD(x): 0.5197\tD(G(z)): 0.5174 / 0.5177\n",
            "[24/100][50/148]\tLoss_D: 1.3804\tLoss_G: 0.6760\tD(x): 0.5215\tD(G(z)): 0.5177 / 0.5177\n",
            "[24/100][100/148]\tLoss_D: 1.3879\tLoss_G: 0.6741\tD(x): 0.5182\tD(G(z)): 0.5183 / 0.5191\n",
            "[25/100][0/148]\tLoss_D: 1.3856\tLoss_G: 0.6748\tD(x): 0.5196\tD(G(z)): 0.5185 / 0.5181\n",
            "[25/100][50/148]\tLoss_D: 1.3857\tLoss_G: 0.6736\tD(x): 0.5193\tD(G(z)): 0.5183 / 0.5177\n",
            "[25/100][100/148]\tLoss_D: 1.3887\tLoss_G: 0.6717\tD(x): 0.5177\tD(G(z)): 0.5182 / 0.5186\n",
            "[26/100][0/148]\tLoss_D: 1.3880\tLoss_G: 0.6722\tD(x): 0.5191\tD(G(z)): 0.5192 / 0.5177\n",
            "[26/100][50/148]\tLoss_D: 1.3850\tLoss_G: 0.6734\tD(x): 0.5205\tD(G(z)): 0.5190 / 0.5183\n",
            "[26/100][100/148]\tLoss_D: 1.3856\tLoss_G: 0.6709\tD(x): 0.5199\tD(G(z)): 0.5188 / 0.5190\n",
            "[27/100][0/148]\tLoss_D: 1.3835\tLoss_G: 0.6733\tD(x): 0.5209\tD(G(z)): 0.5186 / 0.5184\n",
            "[27/100][50/148]\tLoss_D: 1.3845\tLoss_G: 0.6694\tD(x): 0.5192\tD(G(z)): 0.5176 / 0.5185\n",
            "[27/100][100/148]\tLoss_D: 1.3848\tLoss_G: 0.6723\tD(x): 0.5197\tD(G(z)): 0.5182 / 0.5187\n",
            "[28/100][0/148]\tLoss_D: 1.3862\tLoss_G: 0.6707\tD(x): 0.5181\tD(G(z)): 0.5174 / 0.5197\n",
            "[28/100][50/148]\tLoss_D: 1.3855\tLoss_G: 0.6730\tD(x): 0.5195\tD(G(z)): 0.5183 / 0.5176\n",
            "[28/100][100/148]\tLoss_D: 1.3865\tLoss_G: 0.6728\tD(x): 0.5190\tD(G(z)): 0.5184 / 0.5175\n",
            "[29/100][0/148]\tLoss_D: 1.3874\tLoss_G: 0.6746\tD(x): 0.5189\tD(G(z)): 0.5187 / 0.5182\n",
            "[29/100][50/148]\tLoss_D: 1.3856\tLoss_G: 0.6706\tD(x): 0.5196\tD(G(z)): 0.5185 / 0.5189\n",
            "[29/100][100/148]\tLoss_D: 1.3861\tLoss_G: 0.6734\tD(x): 0.5194\tD(G(z)): 0.5185 / 0.5182\n",
            "[30/100][0/148]\tLoss_D: 1.3873\tLoss_G: 0.6713\tD(x): 0.5187\tD(G(z)): 0.5184 / 0.5183\n",
            "[30/100][50/148]\tLoss_D: 1.3833\tLoss_G: 0.6705\tD(x): 0.5199\tD(G(z)): 0.5176 / 0.5176\n",
            "[30/100][100/148]\tLoss_D: 1.3874\tLoss_G: 0.6751\tD(x): 0.5195\tD(G(z)): 0.5192 / 0.5181\n",
            "[31/100][0/148]\tLoss_D: 1.3868\tLoss_G: 0.6718\tD(x): 0.5189\tD(G(z)): 0.5184 / 0.5187\n",
            "[31/100][50/148]\tLoss_D: 1.3913\tLoss_G: 0.6695\tD(x): 0.5181\tD(G(z)): 0.5198 / 0.5192\n",
            "[31/100][100/148]\tLoss_D: 1.3898\tLoss_G: 0.6727\tD(x): 0.5168\tD(G(z)): 0.5179 / 0.5179\n",
            "[32/100][0/148]\tLoss_D: 1.3841\tLoss_G: 0.6773\tD(x): 0.5203\tD(G(z)): 0.5184 / 0.5169\n",
            "[32/100][50/148]\tLoss_D: 1.3865\tLoss_G: 0.6727\tD(x): 0.5182\tD(G(z)): 0.5176 / 0.5185\n",
            "[32/100][100/148]\tLoss_D: 1.3789\tLoss_G: 0.6725\tD(x): 0.5219\tD(G(z)): 0.5174 / 0.5183\n",
            "[33/100][0/148]\tLoss_D: 1.3833\tLoss_G: 0.6706\tD(x): 0.5200\tD(G(z)): 0.5177 / 0.5185\n",
            "[33/100][50/148]\tLoss_D: 1.3865\tLoss_G: 0.6740\tD(x): 0.5179\tD(G(z)): 0.5173 / 0.5178\n",
            "[33/100][100/148]\tLoss_D: 1.3872\tLoss_G: 0.6730\tD(x): 0.5198\tD(G(z)): 0.5194 / 0.5181\n",
            "[34/100][0/148]\tLoss_D: 1.3894\tLoss_G: 0.6691\tD(x): 0.5180\tD(G(z)): 0.5188 / 0.5190\n",
            "[34/100][50/148]\tLoss_D: 1.3878\tLoss_G: 0.6785\tD(x): 0.5189\tD(G(z)): 0.5188 / 0.5186\n",
            "[34/100][100/148]\tLoss_D: 1.3905\tLoss_G: 0.6701\tD(x): 0.5172\tD(G(z)): 0.5186 / 0.5178\n",
            "[35/100][0/148]\tLoss_D: 1.3901\tLoss_G: 0.6775\tD(x): 0.5177\tD(G(z)): 0.5188 / 0.5179\n",
            "[35/100][50/148]\tLoss_D: 1.3856\tLoss_G: 0.6738\tD(x): 0.5195\tD(G(z)): 0.5184 / 0.5187\n",
            "[35/100][100/148]\tLoss_D: 1.3863\tLoss_G: 0.6722\tD(x): 0.5189\tD(G(z)): 0.5181 / 0.5185\n",
            "[36/100][0/148]\tLoss_D: 1.3798\tLoss_G: 0.6721\tD(x): 0.5226\tD(G(z)): 0.5185 / 0.5193\n",
            "[36/100][50/148]\tLoss_D: 1.3867\tLoss_G: 0.6738\tD(x): 0.5197\tD(G(z)): 0.5191 / 0.5180\n",
            "[36/100][100/148]\tLoss_D: 1.3905\tLoss_G: 0.6688\tD(x): 0.5180\tD(G(z)): 0.5193 / 0.5188\n",
            "[37/100][0/148]\tLoss_D: 1.3840\tLoss_G: 0.6781\tD(x): 0.5197\tD(G(z)): 0.5178 / 0.5174\n",
            "[37/100][50/148]\tLoss_D: 1.3866\tLoss_G: 0.6745\tD(x): 0.5196\tD(G(z)): 0.5189 / 0.5182\n",
            "[37/100][100/148]\tLoss_D: 1.3842\tLoss_G: 0.6712\tD(x): 0.5198\tD(G(z)): 0.5179 / 0.5183\n",
            "[38/100][0/148]\tLoss_D: 1.3864\tLoss_G: 0.6758\tD(x): 0.5190\tD(G(z)): 0.5183 / 0.5181\n",
            "[38/100][50/148]\tLoss_D: 1.3845\tLoss_G: 0.6743\tD(x): 0.5199\tD(G(z)): 0.5182 / 0.5179\n",
            "[38/100][100/148]\tLoss_D: 1.3835\tLoss_G: 0.6699\tD(x): 0.5204\tD(G(z)): 0.5181 / 0.5185\n",
            "[39/100][0/148]\tLoss_D: 1.3849\tLoss_G: 0.6718\tD(x): 0.5204\tD(G(z)): 0.5188 / 0.5178\n",
            "[39/100][50/148]\tLoss_D: 1.3904\tLoss_G: 0.6715\tD(x): 0.5175\tD(G(z)): 0.5188 / 0.5183\n",
            "[39/100][100/148]\tLoss_D: 1.3839\tLoss_G: 0.6699\tD(x): 0.5198\tD(G(z)): 0.5178 / 0.5184\n",
            "[40/100][0/148]\tLoss_D: 1.3876\tLoss_G: 0.6720\tD(x): 0.5192\tD(G(z)): 0.5191 / 0.5180\n",
            "[40/100][50/148]\tLoss_D: 1.3883\tLoss_G: 0.6702\tD(x): 0.5182\tD(G(z)): 0.5185 / 0.5190\n",
            "[40/100][100/148]\tLoss_D: 1.3854\tLoss_G: 0.6718\tD(x): 0.5197\tD(G(z)): 0.5184 / 0.5191\n",
            "[41/100][0/148]\tLoss_D: 1.3923\tLoss_G: 0.6706\tD(x): 0.5172\tD(G(z)): 0.5195 / 0.5183\n",
            "[41/100][50/148]\tLoss_D: 1.3920\tLoss_G: 0.6726\tD(x): 0.5165\tD(G(z)): 0.5187 / 0.5185\n",
            "[41/100][100/148]\tLoss_D: 1.3839\tLoss_G: 0.6719\tD(x): 0.5184\tD(G(z)): 0.5165 / 0.5180\n",
            "[42/100][0/148]\tLoss_D: 1.3890\tLoss_G: 0.6758\tD(x): 0.5179\tD(G(z)): 0.5185 / 0.5178\n",
            "[42/100][50/148]\tLoss_D: 1.3822\tLoss_G: 0.6713\tD(x): 0.5201\tD(G(z)): 0.5173 / 0.5182\n",
            "[42/100][100/148]\tLoss_D: 1.3851\tLoss_G: 0.6714\tD(x): 0.5191\tD(G(z)): 0.5177 / 0.5186\n",
            "[43/100][0/148]\tLoss_D: 1.3870\tLoss_G: 0.6718\tD(x): 0.5186\tD(G(z)): 0.5182 / 0.5185\n",
            "[43/100][50/148]\tLoss_D: 1.3844\tLoss_G: 0.6705\tD(x): 0.5207\tD(G(z)): 0.5188 / 0.5194\n",
            "[43/100][100/148]\tLoss_D: 1.3836\tLoss_G: 0.6722\tD(x): 0.5203\tD(G(z)): 0.5181 / 0.5187\n",
            "[44/100][0/148]\tLoss_D: 1.3891\tLoss_G: 0.6736\tD(x): 0.5189\tD(G(z)): 0.5195 / 0.5177\n",
            "[44/100][50/148]\tLoss_D: 1.3848\tLoss_G: 0.6717\tD(x): 0.5196\tD(G(z)): 0.5181 / 0.5185\n",
            "[44/100][100/148]\tLoss_D: 1.3854\tLoss_G: 0.6709\tD(x): 0.5188\tD(G(z)): 0.5176 / 0.5173\n",
            "[45/100][0/148]\tLoss_D: 1.3841\tLoss_G: 0.6731\tD(x): 0.5200\tD(G(z)): 0.5181 / 0.5179\n",
            "[45/100][50/148]\tLoss_D: 1.3810\tLoss_G: 0.6736\tD(x): 0.5213\tD(G(z)): 0.5178 / 0.5188\n",
            "[45/100][100/148]\tLoss_D: 1.3860\tLoss_G: 0.6768\tD(x): 0.5185\tD(G(z)): 0.5176 / 0.5183\n",
            "[46/100][0/148]\tLoss_D: 1.3877\tLoss_G: 0.6692\tD(x): 0.5188\tD(G(z)): 0.5187 / 0.5187\n",
            "[46/100][50/148]\tLoss_D: 1.3896\tLoss_G: 0.6722\tD(x): 0.5180\tD(G(z)): 0.5189 / 0.5185\n",
            "[46/100][100/148]\tLoss_D: 1.3806\tLoss_G: 0.6726\tD(x): 0.5209\tD(G(z)): 0.5173 / 0.5176\n",
            "[47/100][0/148]\tLoss_D: 1.3860\tLoss_G: 0.6694\tD(x): 0.5204\tD(G(z)): 0.5193 / 0.5195\n",
            "[47/100][50/148]\tLoss_D: 1.3868\tLoss_G: 0.6715\tD(x): 0.5192\tD(G(z)): 0.5187 / 0.5168\n",
            "[47/100][100/148]\tLoss_D: 1.3907\tLoss_G: 0.6774\tD(x): 0.5172\tD(G(z)): 0.5187 / 0.5175\n",
            "[48/100][0/148]\tLoss_D: 1.3891\tLoss_G: 0.6732\tD(x): 0.5177\tD(G(z)): 0.5184 / 0.5184\n",
            "[48/100][50/148]\tLoss_D: 1.3889\tLoss_G: 0.6725\tD(x): 0.5173\tD(G(z)): 0.5180 / 0.5178\n",
            "[48/100][100/148]\tLoss_D: 1.3835\tLoss_G: 0.6702\tD(x): 0.5197\tD(G(z)): 0.5175 / 0.5184\n",
            "[49/100][0/148]\tLoss_D: 1.3824\tLoss_G: 0.6714\tD(x): 0.5215\tD(G(z)): 0.5187 / 0.5182\n",
            "[49/100][50/148]\tLoss_D: 1.3883\tLoss_G: 0.6738\tD(x): 0.5186\tD(G(z)): 0.5189 / 0.5179\n",
            "[49/100][100/148]\tLoss_D: 1.3900\tLoss_G: 0.6709\tD(x): 0.5185\tD(G(z)): 0.5196 / 0.5190\n",
            "[50/100][0/148]\tLoss_D: 1.3925\tLoss_G: 0.6727\tD(x): 0.5173\tD(G(z)): 0.5196 / 0.5181\n",
            "[50/100][50/148]\tLoss_D: 1.3823\tLoss_G: 0.6740\tD(x): 0.5207\tD(G(z)): 0.5179 / 0.5182\n",
            "[50/100][100/148]\tLoss_D: 1.3855\tLoss_G: 0.6749\tD(x): 0.5198\tD(G(z)): 0.5186 / 0.5184\n",
            "[51/100][0/148]\tLoss_D: 1.3833\tLoss_G: 0.6756\tD(x): 0.5201\tD(G(z)): 0.5178 / 0.5189\n",
            "[51/100][50/148]\tLoss_D: 1.3881\tLoss_G: 0.6734\tD(x): 0.5187\tD(G(z)): 0.5188 / 0.5186\n",
            "[51/100][100/148]\tLoss_D: 1.3888\tLoss_G: 0.6695\tD(x): 0.5175\tD(G(z)): 0.5181 / 0.5176\n",
            "[52/100][0/148]\tLoss_D: 1.3869\tLoss_G: 0.6698\tD(x): 0.5192\tD(G(z)): 0.5187 / 0.5182\n",
            "[52/100][50/148]\tLoss_D: 1.3859\tLoss_G: 0.6688\tD(x): 0.5188\tD(G(z)): 0.5179 / 0.5186\n",
            "[52/100][100/148]\tLoss_D: 1.3861\tLoss_G: 0.6708\tD(x): 0.5196\tD(G(z)): 0.5187 / 0.5186\n",
            "[53/100][0/148]\tLoss_D: 1.3818\tLoss_G: 0.6728\tD(x): 0.5201\tD(G(z)): 0.5171 / 0.5180\n",
            "[53/100][50/148]\tLoss_D: 1.3887\tLoss_G: 0.6775\tD(x): 0.5188\tD(G(z)): 0.5192 / 0.5181\n",
            "[53/100][100/148]\tLoss_D: 1.3852\tLoss_G: 0.6706\tD(x): 0.5201\tD(G(z)): 0.5188 / 0.5180\n",
            "[54/100][0/148]\tLoss_D: 1.3855\tLoss_G: 0.6807\tD(x): 0.5205\tD(G(z)): 0.5191 / 0.5181\n",
            "[54/100][50/148]\tLoss_D: 1.3898\tLoss_G: 0.6714\tD(x): 0.5176\tD(G(z)): 0.5187 / 0.5186\n",
            "[54/100][100/148]\tLoss_D: 1.3911\tLoss_G: 0.6742\tD(x): 0.5165\tD(G(z)): 0.5182 / 0.5175\n",
            "[55/100][0/148]\tLoss_D: 1.3835\tLoss_G: 0.6709\tD(x): 0.5198\tD(G(z)): 0.5176 / 0.5178\n",
            "[55/100][50/148]\tLoss_D: 1.3844\tLoss_G: 0.6745\tD(x): 0.5200\tD(G(z)): 0.5182 / 0.5184\n",
            "[55/100][100/148]\tLoss_D: 1.3879\tLoss_G: 0.6704\tD(x): 0.5187\tD(G(z)): 0.5188 / 0.5189\n",
            "[56/100][0/148]\tLoss_D: 1.3851\tLoss_G: 0.6714\tD(x): 0.5192\tD(G(z)): 0.5179 / 0.5176\n",
            "[56/100][50/148]\tLoss_D: 1.3862\tLoss_G: 0.6723\tD(x): 0.5196\tD(G(z)): 0.5187 / 0.5173\n",
            "[56/100][100/148]\tLoss_D: 1.3869\tLoss_G: 0.6719\tD(x): 0.5195\tD(G(z)): 0.5190 / 0.5184\n",
            "[57/100][0/148]\tLoss_D: 1.3846\tLoss_G: 0.6715\tD(x): 0.5193\tD(G(z)): 0.5177 / 0.5180\n",
            "[57/100][50/148]\tLoss_D: 1.3905\tLoss_G: 0.6780\tD(x): 0.5172\tD(G(z)): 0.5186 / 0.5180\n",
            "[57/100][100/148]\tLoss_D: 1.3876\tLoss_G: 0.6712\tD(x): 0.5188\tD(G(z)): 0.5187 / 0.5189\n",
            "[58/100][0/148]\tLoss_D: 1.3868\tLoss_G: 0.6730\tD(x): 0.5190\tD(G(z)): 0.5185 / 0.5180\n",
            "[58/100][50/148]\tLoss_D: 1.3852\tLoss_G: 0.6741\tD(x): 0.5198\tD(G(z)): 0.5184 / 0.5184\n",
            "[58/100][100/148]\tLoss_D: 1.3870\tLoss_G: 0.6720\tD(x): 0.5188\tD(G(z)): 0.5183 / 0.5183\n",
            "[59/100][0/148]\tLoss_D: 1.3857\tLoss_G: 0.6735\tD(x): 0.5197\tD(G(z)): 0.5185 / 0.5178\n",
            "[59/100][50/148]\tLoss_D: 1.3886\tLoss_G: 0.6697\tD(x): 0.5185\tD(G(z)): 0.5189 / 0.5191\n",
            "[59/100][100/148]\tLoss_D: 1.3829\tLoss_G: 0.6711\tD(x): 0.5201\tD(G(z)): 0.5176 / 0.5169\n",
            "[60/100][0/148]\tLoss_D: 1.3849\tLoss_G: 0.6720\tD(x): 0.5196\tD(G(z)): 0.5181 / 0.5185\n",
            "[60/100][50/148]\tLoss_D: 1.3883\tLoss_G: 0.6701\tD(x): 0.5188\tD(G(z)): 0.5190 / 0.5186\n",
            "[60/100][100/148]\tLoss_D: 1.3861\tLoss_G: 0.6701\tD(x): 0.5203\tD(G(z)): 0.5193 / 0.5177\n",
            "[61/100][0/148]\tLoss_D: 1.3906\tLoss_G: 0.6713\tD(x): 0.5178\tD(G(z)): 0.5192 / 0.5186\n",
            "[61/100][50/148]\tLoss_D: 1.3876\tLoss_G: 0.6711\tD(x): 0.5184\tD(G(z)): 0.5183 / 0.5172\n",
            "[61/100][100/148]\tLoss_D: 1.3865\tLoss_G: 0.6714\tD(x): 0.5203\tD(G(z)): 0.5196 / 0.5188\n",
            "[62/100][0/148]\tLoss_D: 1.3855\tLoss_G: 0.6690\tD(x): 0.5194\tD(G(z)): 0.5182 / 0.5190\n",
            "[62/100][50/148]\tLoss_D: 1.3843\tLoss_G: 0.6680\tD(x): 0.5190\tD(G(z)): 0.5173 / 0.5190\n",
            "[62/100][100/148]\tLoss_D: 1.3911\tLoss_G: 0.6703\tD(x): 0.5178\tD(G(z)): 0.5194 / 0.5196\n",
            "[63/100][0/148]\tLoss_D: 1.3823\tLoss_G: 0.6703\tD(x): 0.5195\tD(G(z)): 0.5167 / 0.5187\n",
            "[63/100][50/148]\tLoss_D: 1.3852\tLoss_G: 0.6720\tD(x): 0.5198\tD(G(z)): 0.5184 / 0.5182\n",
            "[63/100][100/148]\tLoss_D: 1.3836\tLoss_G: 0.6715\tD(x): 0.5200\tD(G(z)): 0.5179 / 0.5183\n",
            "[64/100][0/148]\tLoss_D: 1.3866\tLoss_G: 0.6780\tD(x): 0.5186\tD(G(z)): 0.5181 / 0.5182\n",
            "[64/100][50/148]\tLoss_D: 1.3871\tLoss_G: 0.6720\tD(x): 0.5198\tD(G(z)): 0.5194 / 0.5189\n",
            "[64/100][100/148]\tLoss_D: 1.3817\tLoss_G: 0.6735\tD(x): 0.5207\tD(G(z)): 0.5177 / 0.5176\n",
            "[65/100][0/148]\tLoss_D: 1.3842\tLoss_G: 0.6724\tD(x): 0.5209\tD(G(z)): 0.5190 / 0.5197\n",
            "[65/100][50/148]\tLoss_D: 1.3845\tLoss_G: 0.6689\tD(x): 0.5201\tD(G(z)): 0.5183 / 0.5195\n",
            "[65/100][100/148]\tLoss_D: 1.3911\tLoss_G: 0.6704\tD(x): 0.5166\tD(G(z)): 0.5183 / 0.5184\n",
            "[66/100][0/148]\tLoss_D: 1.3850\tLoss_G: 0.6746\tD(x): 0.5189\tD(G(z)): 0.5176 / 0.5187\n",
            "[66/100][50/148]\tLoss_D: 1.3875\tLoss_G: 0.6745\tD(x): 0.5188\tD(G(z)): 0.5186 / 0.5193\n",
            "[66/100][100/148]\tLoss_D: 1.3846\tLoss_G: 0.6711\tD(x): 0.5200\tD(G(z)): 0.5183 / 0.5184\n",
            "[67/100][0/148]\tLoss_D: 1.3843\tLoss_G: 0.6767\tD(x): 0.5196\tD(G(z)): 0.5179 / 0.5181\n",
            "[67/100][50/148]\tLoss_D: 1.3846\tLoss_G: 0.6727\tD(x): 0.5197\tD(G(z)): 0.5180 / 0.5191\n",
            "[67/100][100/148]\tLoss_D: 1.3827\tLoss_G: 0.6748\tD(x): 0.5209\tD(G(z)): 0.5182 / 0.5185\n",
            "[68/100][0/148]\tLoss_D: 1.3867\tLoss_G: 0.6734\tD(x): 0.5186\tD(G(z)): 0.5181 / 0.5175\n",
            "[68/100][50/148]\tLoss_D: 1.3848\tLoss_G: 0.6760\tD(x): 0.5194\tD(G(z)): 0.5179 / 0.5188\n",
            "[68/100][100/148]\tLoss_D: 1.3900\tLoss_G: 0.6759\tD(x): 0.5177\tD(G(z)): 0.5188 / 0.5165\n",
            "[69/100][0/148]\tLoss_D: 1.3826\tLoss_G: 0.6744\tD(x): 0.5206\tD(G(z)): 0.5179 / 0.5169\n",
            "[69/100][50/148]\tLoss_D: 1.3868\tLoss_G: 0.6711\tD(x): 0.5194\tD(G(z)): 0.5188 / 0.5180\n",
            "[69/100][100/148]\tLoss_D: 1.3880\tLoss_G: 0.6765\tD(x): 0.5182\tD(G(z)): 0.5183 / 0.5180\n",
            "[70/100][0/148]\tLoss_D: 1.3841\tLoss_G: 0.6732\tD(x): 0.5200\tD(G(z)): 0.5181 / 0.5181\n",
            "[70/100][50/148]\tLoss_D: 1.3881\tLoss_G: 0.6698\tD(x): 0.5184\tD(G(z)): 0.5185 / 0.5180\n",
            "[70/100][100/148]\tLoss_D: 1.3812\tLoss_G: 0.6740\tD(x): 0.5221\tD(G(z)): 0.5186 / 0.5187\n",
            "[71/100][0/148]\tLoss_D: 1.3855\tLoss_G: 0.6717\tD(x): 0.5182\tD(G(z)): 0.5171 / 0.5178\n",
            "[71/100][50/148]\tLoss_D: 1.3909\tLoss_G: 0.6732\tD(x): 0.5170\tD(G(z)): 0.5185 / 0.5184\n",
            "[71/100][100/148]\tLoss_D: 1.3816\tLoss_G: 0.6752\tD(x): 0.5215\tD(G(z)): 0.5182 / 0.5183\n",
            "[72/100][0/148]\tLoss_D: 1.3885\tLoss_G: 0.6783\tD(x): 0.5183\tD(G(z)): 0.5187 / 0.5171\n",
            "[72/100][50/148]\tLoss_D: 1.3880\tLoss_G: 0.6726\tD(x): 0.5181\tD(G(z)): 0.5182 / 0.5183\n",
            "[72/100][100/148]\tLoss_D: 1.3901\tLoss_G: 0.6773\tD(x): 0.5166\tD(G(z)): 0.5179 / 0.5179\n",
            "[73/100][0/148]\tLoss_D: 1.3816\tLoss_G: 0.6753\tD(x): 0.5203\tD(G(z)): 0.5172 / 0.5184\n",
            "[73/100][50/148]\tLoss_D: 1.3839\tLoss_G: 0.6728\tD(x): 0.5192\tD(G(z)): 0.5173 / 0.5183\n",
            "[73/100][100/148]\tLoss_D: 1.3899\tLoss_G: 0.6689\tD(x): 0.5173\tD(G(z)): 0.5184 / 0.5197\n",
            "[74/100][0/148]\tLoss_D: 1.3894\tLoss_G: 0.6729\tD(x): 0.5183\tD(G(z)): 0.5191 / 0.5180\n",
            "[74/100][50/148]\tLoss_D: 1.3833\tLoss_G: 0.6744\tD(x): 0.5205\tD(G(z)): 0.5181 / 0.5182\n",
            "[74/100][100/148]\tLoss_D: 1.3811\tLoss_G: 0.6719\tD(x): 0.5209\tD(G(z)): 0.5175 / 0.5189\n",
            "[75/100][0/148]\tLoss_D: 1.3814\tLoss_G: 0.6720\tD(x): 0.5219\tD(G(z)): 0.5186 / 0.5185\n",
            "[75/100][50/148]\tLoss_D: 1.3863\tLoss_G: 0.6702\tD(x): 0.5185\tD(G(z)): 0.5178 / 0.5176\n",
            "[75/100][100/148]\tLoss_D: 1.3879\tLoss_G: 0.6763\tD(x): 0.5189\tD(G(z)): 0.5190 / 0.5182\n",
            "[76/100][0/148]\tLoss_D: 1.3903\tLoss_G: 0.6723\tD(x): 0.5176\tD(G(z)): 0.5189 / 0.5176\n",
            "[76/100][50/148]\tLoss_D: 1.3889\tLoss_G: 0.6699\tD(x): 0.5179\tD(G(z)): 0.5185 / 0.5186\n",
            "[76/100][100/148]\tLoss_D: 1.3848\tLoss_G: 0.6738\tD(x): 0.5192\tD(G(z)): 0.5177 / 0.5181\n",
            "[77/100][0/148]\tLoss_D: 1.3877\tLoss_G: 0.6772\tD(x): 0.5189\tD(G(z)): 0.5188 / 0.5183\n",
            "[77/100][50/148]\tLoss_D: 1.3857\tLoss_G: 0.6694\tD(x): 0.5193\tD(G(z)): 0.5183 / 0.5189\n",
            "[77/100][100/148]\tLoss_D: 1.3854\tLoss_G: 0.6703\tD(x): 0.5195\tD(G(z)): 0.5182 / 0.5184\n",
            "[78/100][0/148]\tLoss_D: 1.3829\tLoss_G: 0.6772\tD(x): 0.5196\tD(G(z)): 0.5171 / 0.5180\n",
            "[78/100][50/148]\tLoss_D: 1.3818\tLoss_G: 0.6781\tD(x): 0.5216\tD(G(z)): 0.5185 / 0.5173\n",
            "[78/100][100/148]\tLoss_D: 1.3902\tLoss_G: 0.6718\tD(x): 0.5173\tD(G(z)): 0.5186 / 0.5175\n",
            "[79/100][0/148]\tLoss_D: 1.3863\tLoss_G: 0.6741\tD(x): 0.5189\tD(G(z)): 0.5181 / 0.5185\n",
            "[79/100][50/148]\tLoss_D: 1.3881\tLoss_G: 0.6681\tD(x): 0.5184\tD(G(z)): 0.5186 / 0.5190\n",
            "[79/100][100/148]\tLoss_D: 1.3913\tLoss_G: 0.6757\tD(x): 0.5168\tD(G(z)): 0.5185 / 0.5180\n",
            "[80/100][0/148]\tLoss_D: 1.3828\tLoss_G: 0.6731\tD(x): 0.5214\tD(G(z)): 0.5187 / 0.5185\n",
            "[80/100][50/148]\tLoss_D: 1.3867\tLoss_G: 0.6744\tD(x): 0.5201\tD(G(z)): 0.5194 / 0.5184\n",
            "[80/100][100/148]\tLoss_D: 1.3837\tLoss_G: 0.6771\tD(x): 0.5202\tD(G(z)): 0.5181 / 0.5179\n",
            "[81/100][0/148]\tLoss_D: 1.3884\tLoss_G: 0.6715\tD(x): 0.5184\tD(G(z)): 0.5187 / 0.5192\n",
            "[81/100][50/148]\tLoss_D: 1.3874\tLoss_G: 0.6831\tD(x): 0.5185\tD(G(z)): 0.5183 / 0.5183\n",
            "[81/100][100/148]\tLoss_D: 1.3852\tLoss_G: 0.6728\tD(x): 0.5208\tD(G(z)): 0.5193 / 0.5180\n",
            "[82/100][0/148]\tLoss_D: 1.3952\tLoss_G: 0.6724\tD(x): 0.5151\tD(G(z)): 0.5188 / 0.5188\n",
            "[82/100][50/148]\tLoss_D: 1.3895\tLoss_G: 0.6772\tD(x): 0.5180\tD(G(z)): 0.5188 / 0.5181\n",
            "[82/100][100/148]\tLoss_D: 1.3845\tLoss_G: 0.6717\tD(x): 0.5201\tD(G(z)): 0.5184 / 0.5184\n",
            "[83/100][0/148]\tLoss_D: 1.3831\tLoss_G: 0.6695\tD(x): 0.5203\tD(G(z)): 0.5179 / 0.5186\n",
            "[83/100][50/148]\tLoss_D: 1.3865\tLoss_G: 0.6732\tD(x): 0.5181\tD(G(z)): 0.5174 / 0.5189\n",
            "[83/100][100/148]\tLoss_D: 1.3891\tLoss_G: 0.6710\tD(x): 0.5185\tD(G(z)): 0.5191 / 0.5184\n",
            "[84/100][0/148]\tLoss_D: 1.3869\tLoss_G: 0.6781\tD(x): 0.5199\tD(G(z)): 0.5193 / 0.5196\n",
            "[84/100][50/148]\tLoss_D: 1.3873\tLoss_G: 0.6706\tD(x): 0.5184\tD(G(z)): 0.5181 / 0.5186\n",
            "[84/100][100/148]\tLoss_D: 1.3886\tLoss_G: 0.6691\tD(x): 0.5187\tD(G(z)): 0.5190 / 0.5192\n",
            "[85/100][0/148]\tLoss_D: 1.3885\tLoss_G: 0.6740\tD(x): 0.5190\tD(G(z)): 0.5192 / 0.5181\n",
            "[85/100][50/148]\tLoss_D: 1.3876\tLoss_G: 0.6735\tD(x): 0.5186\tD(G(z)): 0.5185 / 0.5181\n",
            "[85/100][100/148]\tLoss_D: 1.3893\tLoss_G: 0.6715\tD(x): 0.5178\tD(G(z)): 0.5185 / 0.5178\n",
            "[86/100][0/148]\tLoss_D: 1.3823\tLoss_G: 0.6746\tD(x): 0.5209\tD(G(z)): 0.5180 / 0.5181\n",
            "[86/100][50/148]\tLoss_D: 1.3877\tLoss_G: 0.6718\tD(x): 0.5193\tD(G(z)): 0.5192 / 0.5187\n",
            "[86/100][100/148]\tLoss_D: 1.3873\tLoss_G: 0.6719\tD(x): 0.5185\tD(G(z)): 0.5183 / 0.5186\n",
            "[87/100][0/148]\tLoss_D: 1.3870\tLoss_G: 0.6711\tD(x): 0.5189\tD(G(z)): 0.5185 / 0.5182\n",
            "[87/100][50/148]\tLoss_D: 1.3890\tLoss_G: 0.6729\tD(x): 0.5186\tD(G(z)): 0.5191 / 0.5176\n",
            "[87/100][100/148]\tLoss_D: 1.3837\tLoss_G: 0.6706\tD(x): 0.5196\tD(G(z)): 0.5176 / 0.5183\n",
            "[88/100][0/148]\tLoss_D: 1.3852\tLoss_G: 0.6730\tD(x): 0.5194\tD(G(z)): 0.5181 / 0.5185\n",
            "[88/100][50/148]\tLoss_D: 1.3879\tLoss_G: 0.6709\tD(x): 0.5188\tD(G(z)): 0.5188 / 0.5180\n",
            "[88/100][100/148]\tLoss_D: 1.3849\tLoss_G: 0.6716\tD(x): 0.5215\tD(G(z)): 0.5198 / 0.5183\n",
            "[89/100][0/148]\tLoss_D: 1.3819\tLoss_G: 0.6721\tD(x): 0.5207\tD(G(z)): 0.5177 / 0.5177\n",
            "[89/100][50/148]\tLoss_D: 1.3853\tLoss_G: 0.6726\tD(x): 0.5207\tD(G(z)): 0.5193 / 0.5187\n",
            "[89/100][100/148]\tLoss_D: 1.3845\tLoss_G: 0.6735\tD(x): 0.5201\tD(G(z)): 0.5184 / 0.5188\n",
            "[90/100][0/148]\tLoss_D: 1.3878\tLoss_G: 0.6758\tD(x): 0.5181\tD(G(z)): 0.5181 / 0.5181\n",
            "[90/100][50/148]\tLoss_D: 1.3890\tLoss_G: 0.6697\tD(x): 0.5193\tD(G(z)): 0.5198 / 0.5186\n",
            "[90/100][100/148]\tLoss_D: 1.3856\tLoss_G: 0.6718\tD(x): 0.5196\tD(G(z)): 0.5184 / 0.5187\n",
            "[91/100][0/148]\tLoss_D: 1.3857\tLoss_G: 0.6656\tD(x): 0.5193\tD(G(z)): 0.5182 / 0.5197\n",
            "[91/100][50/148]\tLoss_D: 1.3889\tLoss_G: 0.6726\tD(x): 0.5176\tD(G(z)): 0.5182 / 0.5180\n",
            "[91/100][100/148]\tLoss_D: 1.3916\tLoss_G: 0.6716\tD(x): 0.5171\tD(G(z)): 0.5190 / 0.5173\n",
            "[92/100][0/148]\tLoss_D: 1.3926\tLoss_G: 0.6781\tD(x): 0.5163\tD(G(z)): 0.5187 / 0.5183\n",
            "[92/100][50/148]\tLoss_D: 1.3858\tLoss_G: 0.6703\tD(x): 0.5194\tD(G(z)): 0.5184 / 0.5186\n",
            "[92/100][100/148]\tLoss_D: 1.3848\tLoss_G: 0.6727\tD(x): 0.5197\tD(G(z)): 0.5182 / 0.5178\n",
            "[93/100][0/148]\tLoss_D: 1.3900\tLoss_G: 0.6730\tD(x): 0.5174\tD(G(z)): 0.5185 / 0.5180\n",
            "[93/100][50/148]\tLoss_D: 1.3849\tLoss_G: 0.6688\tD(x): 0.5193\tD(G(z)): 0.5179 / 0.5189\n",
            "[93/100][100/148]\tLoss_D: 1.3838\tLoss_G: 0.6736\tD(x): 0.5202\tD(G(z)): 0.5182 / 0.5184\n",
            "[94/100][0/148]\tLoss_D: 1.3866\tLoss_G: 0.6764\tD(x): 0.5190\tD(G(z)): 0.5184 / 0.5184\n",
            "[94/100][50/148]\tLoss_D: 1.3846\tLoss_G: 0.6729\tD(x): 0.5209\tD(G(z)): 0.5191 / 0.5196\n",
            "[94/100][100/148]\tLoss_D: 1.3909\tLoss_G: 0.6682\tD(x): 0.5167\tD(G(z)): 0.5183 / 0.5192\n",
            "[95/100][0/148]\tLoss_D: 1.3805\tLoss_G: 0.6717\tD(x): 0.5214\tD(G(z)): 0.5176 / 0.5182\n",
            "[95/100][50/148]\tLoss_D: 1.3876\tLoss_G: 0.6689\tD(x): 0.5200\tD(G(z)): 0.5198 / 0.5186\n",
            "[95/100][100/148]\tLoss_D: 1.3869\tLoss_G: 0.6718\tD(x): 0.5186\tD(G(z)): 0.5182 / 0.5181\n",
            "[96/100][0/148]\tLoss_D: 1.3896\tLoss_G: 0.6744\tD(x): 0.5173\tD(G(z)): 0.5183 / 0.5194\n",
            "[96/100][50/148]\tLoss_D: 1.3826\tLoss_G: 0.6756\tD(x): 0.5208\tD(G(z)): 0.5181 / 0.5181\n",
            "[96/100][100/148]\tLoss_D: 1.3856\tLoss_G: 0.6766\tD(x): 0.5206\tD(G(z)): 0.5193 / 0.5176\n",
            "[97/100][0/148]\tLoss_D: 1.3852\tLoss_G: 0.6771\tD(x): 0.5208\tD(G(z)): 0.5193 / 0.5193\n",
            "[97/100][50/148]\tLoss_D: 1.3871\tLoss_G: 0.6725\tD(x): 0.5175\tD(G(z)): 0.5173 / 0.5184\n",
            "[97/100][100/148]\tLoss_D: 1.3860\tLoss_G: 0.6714\tD(x): 0.5202\tD(G(z)): 0.5192 / 0.5188\n",
            "[98/100][0/148]\tLoss_D: 1.3876\tLoss_G: 0.6761\tD(x): 0.5185\tD(G(z)): 0.5184 / 0.5180\n",
            "[98/100][50/148]\tLoss_D: 1.3865\tLoss_G: 0.6711\tD(x): 0.5199\tD(G(z)): 0.5192 / 0.5175\n",
            "[98/100][100/148]\tLoss_D: 1.3935\tLoss_G: 0.6708\tD(x): 0.5164\tD(G(z)): 0.5193 / 0.5188\n",
            "[99/100][0/148]\tLoss_D: 1.3865\tLoss_G: 0.6692\tD(x): 0.5186\tD(G(z)): 0.5180 / 0.5187\n",
            "[99/100][50/148]\tLoss_D: 1.3861\tLoss_G: 0.6710\tD(x): 0.5186\tD(G(z)): 0.5177 / 0.5181\n",
            "[99/100][100/148]\tLoss_D: 1.3919\tLoss_G: 0.6786\tD(x): 0.5165\tD(G(z)): 0.5185 / 0.5179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fake_warm[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtSFQAiGTLKV",
        "outputId": "c70c8171-c407-4f56-d3a3-9afb0dac0e5d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[0.3402, 0.1984, 0.2649,  ..., 0.0000, 0.5612, 0.0000],\n",
            "        [0.0874, 0.0000, 0.4004,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "       device='cuda:0'), array([2321, 3453]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_warm[-1][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3yQM0mpTTnc",
        "outputId": "4ee3ec08-8aa0-4955-c6d5-99753370d366"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2321, 3453])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(fake_warm[-1][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNu30F6qOBDp",
        "outputId": "d6977ac5-8ec1-473b-b704-a5b2f26a3760"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_warm[-1][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-VAIbr0TwKD",
        "outputId": "d9c23bf5-32e0-446d-fb51-2c6855420df8"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3402, 0.1984, 0.2649,  ..., 0.0000, 0.5612, 0.0000],\n",
              "        [0.0874, 0.0000, 0.4004,  ..., 0.0000, 0.0000, 0.0000]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_warm[-1][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXeDEis4OZD7",
        "outputId": "4a78ce33-68ea-4914-9546-00d7f282ed77"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9.0070,  1.4467, -1.3437,  ...,  0.7178,  1.2286, -0.6926],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings[fake_warm[-1][1][0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTvnxXzPOOS1",
        "outputId": "83cdbdd5-cb88-469d-fc52-c14b77784d83"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_idx = np.random.randint(len(users), size=2)\n",
        "# fake_warm=[(fake, idx)]\n",
        "# print(netD(fake_warm[-1][0], ratings[fake_warm[-1][1][0]]))\n",
        "test_123 = fake_warm[-1][0]\n",
        "print(netD(ratings[fake_warm[-1][1][0]], test_123))\n",
        "# print(netD(fake_warm[-1][0], ratings[fake_warm[-1][1][1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV2aMHizR8So",
        "outputId": "2d1ac6e1-5657-43c1-f1f0-d69f9e190857"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5212],\n",
            "        [0.5217]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2VvehvSeOATb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}