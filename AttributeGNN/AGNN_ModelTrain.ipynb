{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oQGlJ6oIAXoN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE model"
      ],
      "metadata": {
        "id": "FSB6EsxlMBLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        Z_dim = X_dim = h_dim = embed_size\n",
        "        self.Z_dim = Z_dim\n",
        "        self.X_dim= X_dim\n",
        "        self.h_dim = h_dim\n",
        "        self.embed_size= embed_size\n",
        "\n",
        "        def init_weights(m):\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant(m.bias, 0)\n",
        "\n",
        "        # =============================== Q(z|X) ======================================\n",
        "        self.dense_xh = nn.Linear(X_dim, h_dim)\n",
        "        init_weights(self.dense_xh)\n",
        "\n",
        "        self.dense_hz_mu = nn.Linear(h_dim, Z_dim)\n",
        "        init_weights(self.dense_hz_mu)\n",
        "\n",
        "        self.dense_hz_var = nn.Linear(h_dim, Z_dim)\n",
        "        init_weights(self.dense_hz_var)\n",
        "\n",
        "        # =============================== P(X|z) ======================================\n",
        "        self.dense_zh = nn.Linear(Z_dim, h_dim)\n",
        "        init_weights(self.dense_zh)\n",
        "\n",
        "        self.dense_hx = nn.Linear(h_dim, X_dim)\n",
        "        init_weights(self.dense_hx)\n",
        "\n",
        "    def Q(self, X):\n",
        "        h = nn.ReLU()(self.dense_xh(X))\n",
        "        z_mu = self.dense_hz_mu(h)\n",
        "        z_var = self.dense_hz_var(h)\n",
        "        return z_mu, z_var\n",
        "\n",
        "    def sample_z(self, mu, log_var):\n",
        "        mb_size = mu.shape[0]\n",
        "        eps = Variable(torch.randn(mb_size, self.Z_dim)).cuda()\n",
        "        return mu + torch.exp(log_var / 2) * eps\n",
        "\n",
        "    def P(self, z):\n",
        "        h = nn.ReLU()(self.dense_zh(z))\n",
        "        X = self.dense_hx(h)\n",
        "        return X\n"
      ],
      "metadata": {
        "id": "EENVY3LaAgRf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AGNN model"
      ],
      "metadata": {
        "id": "494AJVEXL8jH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AGNN(torch.nn.Module):\n",
        "    def __init__(self, user_size, item_size, gender_size, age_size, occupation_size, genre_size, director_size, writer_size, star_size, country_size, embed_size, attention_size, dropout):\n",
        "        super(AGNN, self).__init__()\n",
        "        self.user_size = user_size\n",
        "        self.item_size = item_size\n",
        "        self.gender_size = gender_size\n",
        "        self.age_size = age_size\n",
        "        self.occupation_size = occupation_size\n",
        "        self.genre_size = genre_size\n",
        "        self.director_size = director_size\n",
        "        self.writer_size = writer_size\n",
        "        self.star_size = star_size\n",
        "        self.country_size = country_size\n",
        "        self.embed_size = embed_size\n",
        "        self.dropout = dropout\n",
        "        self.attention_size = attention_size\n",
        "\n",
        "        def init_weights(m):\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant(m.bias, 0)\n",
        "\n",
        "        self.user_embed = torch.nn.Embedding(self.user_size, self.embed_size)\n",
        "        self.item_embed = torch.nn.Embedding(self.item_size, self.embed_size)\n",
        "        nn.init.xavier_uniform(self.user_embed.weight)\n",
        "        nn.init.xavier_uniform(self.item_embed.weight)\n",
        "\n",
        "        self.user_bias = torch.nn.Embedding(self.user_size, 1)\n",
        "        self.item_bias = torch.nn.Embedding(self.item_size, 1)\n",
        "        nn.init.constant(self.user_bias.weight, 0)\n",
        "        nn.init.constant(self.item_bias.weight, 0)\n",
        "\n",
        "        self.miu = torch.nn.Parameter(torch.zeros(1), requires_grad=True)\n",
        "\n",
        "        self.gender_embed = torch.nn.Embedding(self.gender_size, self.embed_size)\n",
        "        self.gender_embed.weight.data.normal_(0, 0.05)\n",
        "        self.age_embed = torch.nn.Embedding(self.age_size, self.embed_size)\n",
        "        self.age_embed.weight.data.normal_(0, 0.05)\n",
        "        self.occupation_embed = torch.nn.Embedding(self.occupation_size, self.embed_size)\n",
        "        self.occupation_embed.weight.data.normal_(0, 0.05)\n",
        "\n",
        "        self.genre_embed = torch.nn.Embedding(self.genre_size, self.embed_size)\n",
        "        self.genre_embed.weight.data.normal_(0, 0.05)\n",
        "        self.director_embed = torch.nn.Embedding(self.director_size, self.embed_size)\n",
        "        self.director_embed.weight.data.normal_(0, 0.05)\n",
        "        self.writer_embed = torch.nn.Embedding(self.writer_size, self.embed_size)\n",
        "        self.writer_embed.weight.data.normal_(0, 0.05)\n",
        "        self.star_embed = torch.nn.Embedding(self.star_size, self.embed_size)\n",
        "        self.star_embed.weight.data.normal_(0, 0.05)\n",
        "        self.country_embed = torch.nn.Embedding(self.country_size, self.embed_size)\n",
        "        self.country_embed.weight.data.normal_(0, 0.05)\n",
        "\n",
        "\n",
        "        #--------------------------------------------------\n",
        "        self.dense_item_self_biinter = nn.Linear(self.embed_size, self.embed_size)\n",
        "        self.dense_item_self_siinter = nn.Linear(self.embed_size, self.embed_size)\n",
        "        self.dense_item_onehop_biinter = nn.Linear(self.embed_size, self.embed_size)\n",
        "        self.dense_item_onehop_siinter = nn.Linear(self.embed_size, self.embed_size)\n",
        "        self.dense_user_self_biinter = nn.Linear(self.embed_size, self.embed_size)\n",
        "        self.dense_user_self_siinter = nn.Linear(self.embed_size, self.embed_size)\n",
        "        self.dense_user_onehop_biinter = nn.Linear(self.embed_size, self.embed_size)\n",
        "        self.dense_user_onehop_siinter = nn.Linear(self.embed_size, self.embed_size)\n",
        "        init_weights(self.dense_item_self_biinter)\n",
        "        init_weights(self.dense_item_self_siinter)\n",
        "        init_weights(self.dense_item_onehop_biinter)\n",
        "        init_weights(self.dense_item_onehop_siinter)\n",
        "        init_weights(self.dense_user_self_biinter)\n",
        "        init_weights(self.dense_user_self_siinter)\n",
        "        init_weights(self.dense_user_onehop_biinter)\n",
        "        init_weights(self.dense_user_onehop_siinter)\n",
        "\n",
        "        self.dense_item_cate_self = nn.Linear(2 * self.embed_size, self.embed_size)\n",
        "        self.dense_item_cate_hop1 = nn.Linear(2 * self.embed_size, self.embed_size)\n",
        "        self.dense_user_cate_self = nn.Linear(2 * self.embed_size, self.embed_size)\n",
        "        self.dense_user_cate_hop1 = nn.Linear(2 * self.embed_size, self.embed_size)\n",
        "        init_weights(self.dense_item_cate_self)\n",
        "        init_weights(self.dense_item_cate_hop1)\n",
        "        init_weights(self.dense_user_cate_self)\n",
        "        init_weights(self.dense_user_cate_hop1)\n",
        "\n",
        "        self.dense_item_addgate = nn.Linear(self.embed_size * 2, self.embed_size)\n",
        "        init_weights(self.dense_item_addgate)\n",
        "        self.dense_item_erasegate = nn.Linear(self.embed_size * 2, self.embed_size)\n",
        "        init_weights(self.dense_item_erasegate)\n",
        "        self.dense_user_addgate = nn.Linear(self.embed_size * 2, self.embed_size)\n",
        "        init_weights(self.dense_user_addgate)\n",
        "        self.dense_user_erasegate = nn.Linear(self.embed_size * 2, self.embed_size)\n",
        "\n",
        "        self.user_vae = VAE(embed_size)\n",
        "        self.item_vae = VAE(embed_size)\n",
        "\n",
        "        #----------------------------------------------------\n",
        "        #concat, mlp融合\n",
        "        self.FC_pre = nn.Linear(2 * embed_size, 1)\n",
        "        init_weights(self.FC_pre)\n",
        "\n",
        "        \"\"\"# dot\n",
        "        self.user_bias = nn.Embedding(self.user_size, 1)\n",
        "        self.item_bias = nn.Embedding(self.item_size, 1)\n",
        "        self.user_bias.weight.data.normal_(0, 0.01)\n",
        "        self.item_bias.weight.data.normal_(0, 0.01)\n",
        "        self.bias = torch.nn.Parameter(torch.rand(1), requires_grad=True)\n",
        "        self.bias.data.uniform_(0, 0.1)\"\"\"\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.leakyrelu = nn.LeakyReLU()\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def feat_interaction(self, feature_embedding, fun_bi, fun_si, dimension):\n",
        "        summed_features_emb_square = (torch.sum(feature_embedding, dim=dimension)).pow(2)\n",
        "        squared_sum_features_emb = torch.sum(feature_embedding.pow(2), dim=dimension)\n",
        "        deep_fm = 0.5 * (summed_features_emb_square - squared_sum_features_emb)\n",
        "        deep_fm = self.leakyrelu(fun_bi(deep_fm))\n",
        "        bias_fm = self.leakyrelu(fun_si(feature_embedding.sum(dim=dimension)))\n",
        "        nfm = deep_fm + bias_fm\n",
        "        return nfm\n",
        "\n",
        "    def forward(self, user, item, user_self_cate, user_onehop_id, user_onehop_cate, item_self_cate, item_self_director, item_self_writer, item_self_star, item_self_country, item_onehop_id, item_onehop_cate, item_onehop_director, item_onehop_writer, item_onehop_star, item_onehop_country, mode='train'):\n",
        "\n",
        "        uids_list = user.cuda()\n",
        "        sids_list = item.cuda()\n",
        "        if mode == 'train' or mode == 'warm':\n",
        "            user_embedding = self.user_embed(torch.autograd.Variable(uids_list))\n",
        "            item_embedding = self.item_embed(torch.autograd.Variable(sids_list))\n",
        "        if mode == 'ics':\n",
        "            user_embedding = self.user_embed(torch.autograd.Variable(uids_list))\n",
        "        if mode == 'ucs':\n",
        "            item_embedding = self.item_embed(torch.autograd.Variable(sids_list))\n",
        "\n",
        "        batch_size = item_self_cate.shape[0]\n",
        "        cate_size = item_self_cate.shape[1]\n",
        "        director_size = item_self_director.shape[1]\n",
        "        writer_size = item_self_writer.shape[1]\n",
        "        star_size = item_self_star.shape[1]\n",
        "        country_size = item_self_country.shape[1]\n",
        "        user_onehop_size = user_onehop_id.shape[1]\n",
        "        item_onehop_size = item_onehop_id.shape[1]\n",
        "\n",
        "        #------------------------------------------------------GCN-item\n",
        "        # K=2\n",
        "        item_onehop_id = self.item_embed(Variable(item_onehop_id))\n",
        "\n",
        "        item_onehop_cate = self.genre_embed(Variable(item_onehop_cate).view(-1, cate_size)).view(batch_size,item_onehop_size,cate_size, -1)\n",
        "        item_onehop_director = self.director_embed(Variable(item_onehop_director).view(-1, director_size)).view(batch_size, item_onehop_size, director_size, -1)\n",
        "        item_onehop_writer = self.writer_embed(Variable(item_onehop_writer).view(-1, writer_size)).view(batch_size, item_onehop_size, writer_size, -1)\n",
        "        item_onehop_star = self.star_embed(Variable(item_onehop_star).view(-1, star_size)).view(batch_size, item_onehop_size, star_size, -1)\n",
        "        item_onehop_country = self.country_embed(Variable(item_onehop_country).view(-1, country_size)).view(batch_size, item_onehop_size, country_size, -1)\n",
        "\n",
        "        item_onehop_feature = torch.cat([item_onehop_cate, item_onehop_director, item_onehop_writer, item_onehop_star, item_onehop_country], dim=2)\n",
        "        item_onehop_embed = self.dense_item_cate_hop1(torch.cat([self.feat_interaction(item_onehop_feature, self.dense_item_onehop_biinter,  self.dense_item_onehop_siinter, dimension=2), item_onehop_id], dim=-1))\n",
        "\n",
        "        # K=1\n",
        "        item_self_cate = self.genre_embed(Variable(item_self_cate))\n",
        "        item_self_director = self.director_embed(Variable(item_self_director))\n",
        "        item_self_writer = self.writer_embed(Variable(item_self_writer))\n",
        "        item_self_star = self.star_embed(Variable(item_self_star))\n",
        "        item_self_country = self.country_embed(Variable(item_self_country))\n",
        "\n",
        "        item_self_feature = torch.cat([item_self_cate, item_self_director, item_self_writer, item_self_star, item_self_country], dim=1)\n",
        "        item_self_feature = self.feat_interaction(item_self_feature, self.dense_item_self_biinter, self.dense_item_self_siinter, dimension=1)\n",
        "\n",
        "        if mode == 'ics':\n",
        "            item_mu, item_var = self.item_vae.Q(item_self_feature)\n",
        "            item_z = self.item_vae.sample_z(item_mu, item_var)\n",
        "            item_embedding = self.item_vae.P(item_z)\n",
        "        item_self_embed = self.dense_item_cate_self(torch.cat([item_self_feature, item_embedding], dim=-1))\n",
        "\n",
        "        item_addgate = self.sigmoid(self.dense_item_addgate(torch.cat([item_self_embed.unsqueeze(1).repeat(1, item_onehop_size, 1), item_onehop_embed], dim=-1)))  # 商品的邻居门，控制邻居信息多少作为输入\n",
        "        item_erasegate = self.sigmoid(self.dense_item_erasegate(torch.cat([item_self_embed, item_onehop_embed.mean(dim=1)], dim=-1)))\n",
        "        item_onehop_embed_final = (item_onehop_embed * item_addgate).mean(1)\n",
        "        item_self_embed = (1 - item_erasegate) * item_self_embed\n",
        "\n",
        "        item_gcn_embed = self.leakyrelu(item_self_embed + item_onehop_embed_final)  # [batch, embed]\n",
        "\n",
        "        #----------------------------------------------------------GCN-user\n",
        "        # K=2\n",
        "        user_onehop_id = self.user_embed(Variable(user_onehop_id))\n",
        "\n",
        "        user_onehop_gender_emb = self.gender_embed(Variable(user_onehop_cate[:, :, 0]))\n",
        "        user_onehop_age_emb = self.age_embed(Variable(user_onehop_cate[:, :, 1]))\n",
        "        user_onehop_occupation_emb = self.occupation_embed(Variable(user_onehop_cate[:, :, 2]))\n",
        "\n",
        "        user_onehop_feat = torch.cat([user_onehop_gender_emb.unsqueeze(2), user_onehop_age_emb.unsqueeze(2), user_onehop_occupation_emb.unsqueeze(2)], dim=2)\n",
        "        user_onehop_embed = self.dense_user_cate_hop1(torch.cat([self.feat_interaction(user_onehop_feat, self.dense_user_onehop_biinter, self.dense_user_onehop_siinter, dimension=2), user_onehop_id], dim=-1))\n",
        "\n",
        "        # K=1\n",
        "        user_gender_emb = self.gender_embed(Variable(user_self_cate[:, 0]))\n",
        "        user_age_emb = self.age_embed(Variable(user_self_cate[:, 1]))\n",
        "        user_occupation_emb = self.occupation_embed(Variable(user_self_cate[:, 2]))\n",
        "\n",
        "        user_self_feature = torch.cat([user_gender_emb.unsqueeze(1), user_age_emb.unsqueeze(1), user_occupation_emb.unsqueeze(1)], dim=1)\n",
        "        user_self_feature = self.feat_interaction(user_self_feature, self.dense_user_self_biinter,  self.dense_user_onehop_siinter, dimension=1)\n",
        "\n",
        "        if mode == 'ucs':\n",
        "            user_mu, user_var = self.user_vae.Q(user_self_feature)\n",
        "            user_z = self.user_vae.sample_z(user_mu, user_var)\n",
        "            user_embedding = self.user_vae.P(user_z)\n",
        "        user_self_embed = self.dense_user_cate_self(torch.cat([user_self_feature, user_embedding], dim=-1))\n",
        "\n",
        "        user_addgate = self.sigmoid(self.dense_user_addgate(torch.cat([user_self_embed.unsqueeze(1).repeat(1, user_onehop_size, 1), user_onehop_embed],dim=-1)))\n",
        "        user_erasegate = self.sigmoid(self.dense_user_erasegate(torch.cat([user_self_embed, user_onehop_embed.mean(dim=1)], dim=-1)))\n",
        "        user_onehop_embed_final = (user_onehop_embed * user_addgate).mean(dim=1)\n",
        "        user_self_embed = (1 - user_erasegate) * user_self_embed\n",
        "\n",
        "        user_gcn_embed = self.leakyrelu(user_self_embed + user_onehop_embed_final)\n",
        "\n",
        "        #--------------------------------------------------norm\n",
        "        item_mu, item_var = self.item_vae.Q(item_self_feature)\n",
        "        item_z = self.item_vae.sample_z(item_mu, item_var)\n",
        "        item_preference_sample = self.item_vae.P(item_z)\n",
        "\n",
        "        user_mu, user_var = self.user_vae.Q(user_self_feature)\n",
        "        user_z = self.user_vae.sample_z(user_mu, user_var)\n",
        "        user_preference_sample = self.user_vae.P(user_z)\n",
        "\n",
        "        recon_loss = torch.norm(item_preference_sample - item_embedding) + torch.norm(user_preference_sample - user_embedding)\n",
        "        kl_loss = torch.mean(0.5 * torch.sum(torch.exp(item_z) + item_mu ** 2 - 1. - item_var, 1)) + \\\n",
        "                  torch.mean(0.5 * torch.sum(torch.exp(user_z) + user_mu ** 2 - 1. - user_var, 1))\n",
        "\n",
        "        ####################################prediction#####################################################\n",
        "\n",
        "        #concat -> mlp\n",
        "        bu = self.user_bias(Variable(uids_list))\n",
        "        bi = self.item_bias(Variable(sids_list))\n",
        "        #pred = (user_gcn_embed * item_gcn_embed).sum(1, keepdim=True) + bu + bi + (self.miu).repeat(batch_size, 1)\n",
        "        tmp = torch.cat([user_gcn_embed, item_gcn_embed], dim=1)\n",
        "        pred = self.FC_pre(tmp) + (user_gcn_embed * item_gcn_embed).sum(1, keepdim=True) + bu + bi + (self.miu).repeat(batch_size, 1)\n",
        "\n",
        "        return pred.squeeze(), recon_loss, kl_loss\n"
      ],
      "metadata": {
        "id": "Cih2VtQQAiRw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc72AnWTBQDZ",
        "outputId": "e8be0a75-742e-4292-939f-854f9c9ad468"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, argparse\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tensorboardX import SummaryWriter\n",
        "from collections import OrderedDict\n",
        "import json\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "Xxbc5bXlBFqs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_list(ftrain, batch_size):\n",
        "    f = open(ftrain, 'r')\n",
        "    train_list = []\n",
        "    for eachline in f:\n",
        "        eachline = eachline.strip().split('\\t')\n",
        "        u, i, l = int(eachline[0]), int(eachline[1]), float(eachline[2])\n",
        "        train_list.append([u, i, l])\n",
        "    num_batches_per_epoch = int((len(train_list) - 1) / batch_size) + 1\n",
        "    return num_batches_per_epoch, train_list\n",
        "\n",
        "def get_batch_instances(train_list, user_feature_dict, item_feature_dict, item_director_dict, item_writer_dict, item_star_dict, item_country_dict, batch_size, user_nei_dict, item_nei_dict, shuffle=True):\n",
        "    num_batches_per_epoch = int((len(train_list) - 1) / batch_size) + 1\n",
        "    def data_generator(train_list):\n",
        "        data_size = len(train_list)\n",
        "        user_feature_arr = np.array(list(user_feature_dict.values()))\n",
        "        max_user_cate_size = user_feature_arr.shape[1]\n",
        "\n",
        "        item_genre_arr = np.array(list(item_feature_dict.values())) #len=6 ,0\n",
        "        item_director_arr = np.array(list(item_director_dict.values())) #len=3 ,6\n",
        "        item_writer_arr = np.array(list(item_writer_dict.values())) #len=3, 9\n",
        "        item_star_arr = np.array(list(item_star_dict.values())) #len=3, 12\n",
        "        item_country_arr = np.array(list(item_country_dict.values()))   #len=8, 15\n",
        "\n",
        "        item_feature_arr = np.concatenate([item_genre_arr, item_director_arr, item_writer_arr, item_star_arr, item_country_arr], axis=1)\n",
        "        max_item_cate_size = item_feature_arr.shape[1]\n",
        "\n",
        "        item_layer1_nei_num = FLAGS.item_layer1_nei_num\n",
        "        user_layer1_nei_num = FLAGS.user_layer1_nei_num\n",
        "\n",
        "        if shuffle == True:\n",
        "            np.random.shuffle(train_list)\n",
        "        train_list = np.array(train_list)\n",
        "\n",
        "        for batch_num in range(num_batches_per_epoch):\n",
        "            start_index = batch_num * batch_size\n",
        "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
        "            current_batch_size = end_index - start_index\n",
        "\n",
        "            u = train_list[start_index: end_index][:, 0].astype(np.int64)\n",
        "            i = train_list[start_index: end_index][:, 1].astype(np.int64)\n",
        "            l = train_list[start_index: end_index][:, 2]\n",
        "\n",
        "            i_self_cate = np.zeros([current_batch_size, max_item_cate_size], dtype=np.int64)\n",
        "            i_onehop_id = np.zeros([current_batch_size, item_layer1_nei_num], dtype=np.int64)\n",
        "            i_onehop_cate = np.zeros([current_batch_size, item_layer1_nei_num, max_item_cate_size], dtype=np.int64)\n",
        "\n",
        "            u_self_cate = np.zeros([current_batch_size, max_user_cate_size], dtype=np.int64)\n",
        "            u_onehop_id = np.zeros([current_batch_size, user_layer1_nei_num], dtype=np.int64)\n",
        "            u_onehop_cate = np.zeros([current_batch_size, user_layer1_nei_num, max_user_cate_size], dtype=np.int64)\n",
        "\n",
        "            for index, each_i in enumerate(i):\n",
        "                i_self_cate[index] = item_feature_arr[each_i]    #item_self_cate\n",
        "\n",
        "                tmp_one_nei = item_nei_dict[each_i][0]\n",
        "                tmp_prob = item_nei_dict[each_i][1]\n",
        "                if len(tmp_one_nei) > item_layer1_nei_num:  #re-sampling\n",
        "                    tmp_one_nei = np.random.choice(tmp_one_nei, item_layer1_nei_num, replace=False, p=tmp_prob)\n",
        "                elif len(tmp_one_nei) < item_layer1_nei_num:\n",
        "                    tmp_one_nei = np.random.choice(tmp_one_nei, item_layer1_nei_num, replace=True, p=tmp_prob)\n",
        "                tmp_one_nei[-1] = each_i\n",
        "\n",
        "                i_onehop_id[index] = tmp_one_nei    #item_1_neigh\n",
        "                i_onehop_cate[index] = item_feature_arr[tmp_one_nei]  #item_1_neigh_cate\n",
        "\n",
        "            for index, each_u in enumerate(u):\n",
        "                u_self_cate[index] = user_feature_dict[each_u]  # item_self_cate\n",
        "\n",
        "                tmp_one_nei = user_nei_dict[each_u][0]\n",
        "                tmp_prob = user_nei_dict[each_u][1]\n",
        "                if len(tmp_one_nei) > user_layer1_nei_num:  # re-sampling\n",
        "                    tmp_one_nei = np.random.choice(tmp_one_nei, user_layer1_nei_num, replace=False, p=tmp_prob)\n",
        "                elif len(tmp_one_nei) < user_layer1_nei_num:\n",
        "                    tmp_one_nei = np.random.choice(tmp_one_nei, user_layer1_nei_num, replace=True, p=tmp_prob)\n",
        "                tmp_one_nei[-1] = each_u\n",
        "\n",
        "                u_onehop_id[index] = tmp_one_nei  # user_1_neigh\n",
        "                u_onehop_cate[index] = user_feature_arr[tmp_one_nei]  # user_1_neigh_cate\n",
        "\n",
        "            yield ([u, i, l, u_self_cate, u_onehop_id, u_onehop_cate, i_self_cate, i_onehop_id, i_onehop_cate])\n",
        "    return data_generator(train_list)\n"
      ],
      "metadata": {
        "id": "gWoCLeAIAmU2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics(model, test_dataloader):\n",
        "    label_lst, pred_lst = [], []\n",
        "    rmse, mse, mae = 0,0,0\n",
        "    count = 0\n",
        "    for batch_data in test_dataloader:\n",
        "        user = torch.LongTensor(batch_data[0]).cuda()\n",
        "        item = torch.LongTensor(batch_data[1]).cuda()\n",
        "        label = torch.FloatTensor(batch_data[2]).cuda()\n",
        "        user_self_cate = torch.LongTensor(batch_data[3]).cuda()\n",
        "        user_onehop_id = torch.LongTensor(batch_data[4]).cuda()\n",
        "        user_onehop_cate = torch.LongTensor(batch_data[5]).cuda()\n",
        "        item_self_cate, item_self_director, item_self_writer, item_self_star, item_self_country = torch.LongTensor(\n",
        "            batch_data[6])[:, 0:6].cuda(), torch.LongTensor(batch_data[6])[:, 6:9].cuda(), torch.LongTensor(\n",
        "            batch_data[6])[:, 9:12].cuda(), torch.LongTensor(batch_data[6])[:, 12:15].cuda(), torch.LongTensor(\n",
        "            batch_data[6])[:, 15:].cuda()\n",
        "        item_onehop_id = torch.LongTensor(batch_data[7]).cuda()\n",
        "        item_onehop_cate, item_onehop_director, item_onehop_writer, item_onehop_star, item_onehop_country = torch.LongTensor(\n",
        "            batch_data[8])[:, :, 0:6].cuda(), torch.LongTensor(batch_data[8])[:, :, 6:9].cuda(), torch.LongTensor(\n",
        "            batch_data[8])[:, :, 9:12].cuda(), torch.LongTensor(batch_data[8])[:, :, 12:15].cuda(), torch.LongTensor(\n",
        "            batch_data[8])[:, :, 15:].cuda()\n",
        "\n",
        "        prediction, recon_loss, kl_loss = model(user, item, user_self_cate, user_onehop_id, user_onehop_cate, item_self_cate,\n",
        "                           item_self_director, item_self_writer, item_self_star, item_self_country, item_onehop_id,\n",
        "                           item_onehop_cate, item_onehop_director, item_onehop_writer, item_onehop_star,\n",
        "                           item_onehop_country, mode = mode)\n",
        "        prediction = prediction.cpu().data.numpy()\n",
        "        prediction = prediction.reshape(prediction.shape[0])\n",
        "        label = label.cpu().numpy()\n",
        "        my_rmse = np.sum((prediction - label) ** 2)\n",
        "        my_mse = np.sum((prediction - label) ** 2)\n",
        "        my_mae = np.sum(np.abs(prediction - label))\n",
        "        # my_rmse = torch.sqrt(torch.sum((prediction - label) ** 2) / FLAGS.batch_size)\n",
        "        rmse+=my_rmse\n",
        "        mse+=my_mse\n",
        "        mae+=my_mae\n",
        "        count += len(user)\n",
        "        label_lst.extend(list([float(l) for l in label]))\n",
        "        pred_lst.extend(list([float(l) for l in prediction]))\n",
        "\n",
        "    my_mse = mse/count\n",
        "    my_rmse = np.sqrt(rmse/count)\n",
        "    my_mae = mae/count\n",
        "    return my_rmse, my_mse, my_mae, label_lst, pred_lst"
      ],
      "metadata": {
        "id": "8OUeqibJA6vK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--lr\", default=0.0005, type=float,\n",
        "\t\t\t\t\thelp=\"learning rate.\")\n",
        "parser.add_argument(\"--dropout\", default=0.5, type=float,\n",
        "\t\t\t\t\thelp=\"dropout rate.\")\n",
        "parser.add_argument(\"--batch_size\", default=128, type=int,\n",
        "\t\t\t\t\thelp=\"batch size when training.\")\n",
        "parser.add_argument(\"--gpu\", default=\"0\", type=str,\n",
        "\t\t\t\t\thelp=\"gpu card ID.\")\n",
        "parser.add_argument(\"--epochs\", default=20, type=str,\n",
        "\t\t\t\t\thelp=\"training epoches.\")\n",
        "parser.add_argument(\"--clip_norm\", default=5.0, type=float,\n",
        "\t\t\t\t\thelp=\"clip norm for preventing gradient exploding.\")\n",
        "parser.add_argument(\"--embed_size\", default=30, type=int, help=\"embedding size for users and items.\")\n",
        "parser.add_argument(\"--attention_size\", default=50, type=int, help=\"embedding size for users and items.\")\n",
        "parser.add_argument(\"--item_layer1_nei_num\", default=10, type=int)\n",
        "parser.add_argument(\"--user_layer1_nei_num\", default=10, type=int)\n",
        "parser.add_argument(\"--vae_lambda\", default=1, type=int)\n",
        "\"\"\"\n",
        "class Flags:\n",
        "  def __init__(self, lr, dropout, batch_size, gpu, epochs, clip_norm, embed_size, attention_size, item_layer1_nei_num, user_layer1_nei_num, vae_lambda):\n",
        "    self.batch_size = batch_size\n",
        "    self.lr = lr\n",
        "    self.dropout = dropout\n",
        "    self.gpu = gpu\n",
        "    self.epochs = epochs\n",
        "    self.clip_norm = clip_norm\n",
        "    self.embed_size = embed_size\n",
        "    self.attention_size = attention_size\n",
        "    self.item_layer1_nei_num = item_layer1_nei_num\n",
        "    self.user_layer1_nei_num = user_layer1_nei_num\n",
        "    self.vae_lambda = vae_lambda"
      ],
      "metadata": {
        "id": "Asut8MsFBDsS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "543pubABFJm5",
        "outputId": "d2bb2beb-29b2-482c-b15b-fafd014fd205"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/CS247/project/AttributeGNN/code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klD_gGqjFTBy",
        "outputId": "d3645be8-bbc2-4068-ac65-2143ceb3ff7c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS247/project/AttributeGNN/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## item cold start train loop"
      ],
      "metadata": {
        "id": "0M0RZIMiL32F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FLAGS = Flags(lr=0.0005, dropout=0.5, batch_size=128, gpu=0,\n",
        "              epochs=20, clip_norm=5.0, embed_size=40,\n",
        "              attention_size=50, # not specified in paper so leave as argparse default\n",
        "              item_layer1_nei_num=10, # use argparse default\n",
        "              user_layer1_nei_num=10, # use argparse default\n",
        "              vae_lambda=1)\n",
        "mode = 'ics'"
      ],
      "metadata": {
        "id": "-n3hFIE8GKbu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop():\n",
        "    #item cold start\n",
        "    f_info = '../ml100k/uiinfo.pkl'\n",
        "    f_neighbor = '../ml100k/neighbor_aspect_extension_2_zscore_ics_uuii_0.20.pkl'\n",
        "    f_train = '../ml100k/ics_train.dat'\n",
        "    f_test = '../ml100k/ics_val.dat'\n",
        "    f_model = '../ml100k/agnn_ics_'\n",
        "\n",
        "    \"\"\"# user cold start\n",
        "    f_info = '../ml100k/uiinfo.pkl'\n",
        "    f_neighbor = '../ml100k/neighbor_aspect_extension_2_zscore_ucs_uuii.pkl'\n",
        "    f_train = '../ml100k/ucs_train.dat'\n",
        "    f_test = '../ml100k/ucs_val.dat'\n",
        "    f_model = '../ml100k/agnn_ucs_'\n",
        "    mode = 'ucs'\"\"\"\n",
        "\n",
        "    \"\"\"# warm start\n",
        "    f_info = '../ml100k/uiinfo.pkl'\n",
        "    f_neighbor = '../ml100k/neighbor_aspect_extension_2_zscore_warm_uuii.pkl'\n",
        "    f_train = '../ml100k/warm_train.dat'\n",
        "    f_test = '../ml100k/warm_val.dat'\n",
        "    f_model = '../ml100k/agnn_warm_'\n",
        "    mode = 'warm'\"\"\"\n",
        "\n",
        "    # use best hyperparameters from paper\n",
        "    # see section 4.1.4 and 4.3 for description of how they got them\n",
        "\n",
        "    print(\"\\nParameters:\")\n",
        "    print(FLAGS)\n",
        "\n",
        "    with open(f_neighbor, 'rb') as f:\n",
        "        neighbor_dict = pickle.load(f)\n",
        "    user_nei_dict = neighbor_dict['user_nei_dict']\n",
        "    item_nei_dict = neighbor_dict['item_nei_dict']\n",
        "    director_num = neighbor_dict['director_num']\n",
        "    writer_num = neighbor_dict['writer_num']\n",
        "    star_num = neighbor_dict['star_num']\n",
        "    country_num = neighbor_dict['country_num']\n",
        "\n",
        "    item_director_dict = neighbor_dict['item_director_dict']    #dict[i]=[x,x,x]\n",
        "    item_writer_dict = neighbor_dict['item_writer_dict']        #dict[i]=[x,x,x]\n",
        "    item_star_dict = neighbor_dict['item_star_dict']            #dict[i]=[x,x,x]\n",
        "    item_country_dict = neighbor_dict['item_country_dict']      #dict[i]=[x,x,x,x,x,x,x,x]\n",
        "\n",
        "    with open(f_info, 'rb') as f:\n",
        "        item_info = pickle.load(f)\n",
        "    user_num = item_info['user_num']\n",
        "    item_num = item_info['item_num']\n",
        "    gender_num = item_info['gender_num']\n",
        "    age_num = item_info['age_num']\n",
        "    occupation_num = item_info['occupation_num']\n",
        "    genre_num = item_info['genre_num']\n",
        "    user_feature_dict = item_info['user_feature_dict']  #gender, age, occupation    dict[u]=[x,x,x]\n",
        "    item_feature_dict = item_info['item_feature_dict']  #genre                      dict[i]=[x,x,x,x,x,x]\n",
        "\n",
        "    print(\"user_num {}, item_num {}, gender_num {}, age_num {}, occupation_num {}, genre_num {}, director_num {}, writer_num {}, star_num {}, country_num {}, mode {} \".format(user_num, item_num, gender_num, age_num, occupation_num, genre_num, director_num, writer_num, star_num, country_num, mode))\n",
        "\n",
        "    train_steps, train_list = get_data_list(f_train, batch_size=FLAGS.batch_size)\n",
        "    test_steps, test_list = get_data_list(f_test, batch_size=FLAGS.batch_size)\n",
        "\n",
        "    model = AGNN(user_num, item_num, gender_num, age_num, occupation_num, genre_num, director_num, writer_num, star_num, country_num, FLAGS.embed_size, FLAGS.attention_size, FLAGS.dropout)\n",
        "    model.cuda()\n",
        "\n",
        "    loss_function = torch.nn.MSELoss(size_average=False)\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=FLAGS.lr, weight_decay=0.001)\n",
        "\n",
        "    writer = SummaryWriter()  # For visualization\n",
        "    #f_loss_curve = open('tmp_loss_curve.txt', 'w')\n",
        "    best_rmse = 5\n",
        "\n",
        "    count = 0\n",
        "    for epoch in range(FLAGS.epochs):\n",
        "        #tmp_main_loss, tmp_vae_loss = [], []\n",
        "        model.train()  # Enable dropout (if have).\n",
        "        start_time = time.time()\n",
        "        train_dataloader = get_batch_instances(train_list, user_feature_dict, item_feature_dict, item_director_dict, item_writer_dict, item_star_dict, item_country_dict,  batch_size=FLAGS.batch_size, user_nei_dict=user_nei_dict, item_nei_dict=item_nei_dict, shuffle=True)\n",
        "\n",
        "        for idx, batch_data in enumerate(train_dataloader): #u, i, l, u_self_cate, u_onehop_id, u_onehop_rating, u_onehop_cate, i_self_cate, i_onehop_id, i_onehop_cate\n",
        "            user = torch.LongTensor(batch_data[0]).cuda()\n",
        "            item = torch.LongTensor(batch_data[1]).cuda()\n",
        "            label = torch.FloatTensor(batch_data[2]).cuda()\n",
        "            user_self_cate = torch.LongTensor(batch_data[3]).cuda()\n",
        "            user_onehop_id = torch.LongTensor(batch_data[4]).cuda()\n",
        "            user_onehop_cate = torch.LongTensor(batch_data[5]).cuda()\n",
        "            item_self_cate, item_self_director, item_self_writer, item_self_star, item_self_country = torch.LongTensor(batch_data[6])[:, 0:6].cuda(), torch.LongTensor(batch_data[6])[:, 6:9].cuda(), torch.LongTensor(batch_data[6])[:, 9:12].cuda(), torch.LongTensor(batch_data[6])[:, 12:15].cuda(), torch.LongTensor(batch_data[6])[:, 15:].cuda()\n",
        "            item_onehop_id = torch.LongTensor(batch_data[7]).cuda()\n",
        "            item_onehop_cate, item_onehop_director, item_onehop_writer, item_onehop_star, item_onehop_country = torch.LongTensor(batch_data[8])[:, :, 0:6].cuda(), torch.LongTensor(batch_data[8])[:, :, 6:9].cuda(), torch.LongTensor(batch_data[8])[:, :, 9:12].cuda(), torch.LongTensor(batch_data[8])[:, :, 12:15].cuda(), torch.LongTensor(batch_data[8])[:, :, 15:].cuda()\n",
        "\n",
        "            model.zero_grad()\n",
        "            prediction, recon_loss, kl_loss = model(user, item, user_self_cate, user_onehop_id, user_onehop_cate, item_self_cate, item_self_director, item_self_writer, item_self_star, item_self_country, item_onehop_id, item_onehop_cate, item_onehop_director, item_onehop_writer, item_onehop_star, item_onehop_country, mode='train')\n",
        "\n",
        "            label = Variable(label)\n",
        "\n",
        "            main_loss = loss_function(prediction, label)\n",
        "            loss = main_loss + FLAGS.vae_lambda * (recon_loss + kl_loss)\n",
        "\n",
        "            loss.backward()\n",
        "            # nn.utils.clip_grad_norm(model.parameters(), FLAGS.clip_norm)\n",
        "            optimizer.step()\n",
        "            writer.add_scalar('data/loss', loss.data, count)\n",
        "            count += 1\n",
        "\n",
        "        tmploss = torch.sqrt(loss / FLAGS.batch_size)\n",
        "        print(50 * '#')\n",
        "        print('epoch: ', epoch, '     ', tmploss.detach())\n",
        "\n",
        "        model.eval()\n",
        "        print('time = ', time.time() - start_time)\n",
        "        test_dataloader = get_batch_instances(test_list, user_feature_dict, item_feature_dict, item_director_dict, item_writer_dict, item_star_dict, item_country_dict, batch_size=FLAGS.batch_size, user_nei_dict=user_nei_dict, item_nei_dict=item_nei_dict, shuffle=False)\n",
        "        rmse, mse, mae, label_lst, pred_lst = metrics(model, test_dataloader)\n",
        "        print('test rmse,mse,mae: ', rmse,mse,mae)\n",
        "\n",
        "        \"\"\"if (rmse < best_rmse):\n",
        "            best_rmse = rmse\n",
        "            f_name = f_model + str(best_rmse)[:7] + '.dat' #f_model + str(best_rmse)[:7] + '.dat'\n",
        "            #torch.save(model, f_name)\n",
        "            f = open(f_name, 'w')\n",
        "            res_dict = {}\n",
        "            res_dict['label'] = label_lst\n",
        "            res_dict['pred'] = pred_lst\n",
        "            json.dump(res_dict, f)\n",
        "            f.close()\n",
        "            print('save result ok')\"\"\""
      ],
      "metadata": {
        "id": "9mTKO4HuA9FU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## item cold start evaluation"
      ],
      "metadata": {
        "id": "G51O0oTGMMhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xynWAMNTFpXq",
        "outputId": "75177ef8-3a82-42e7-c9a2-bfe57921e92a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Parameters:\n",
            "<__main__.Flags object at 0x7a89dedb2230>\n",
            "user_num 944, item_num 1683, gender_num 2, age_num 7, occupation_num 21, genre_num 19, director_num 1112, writer_num 2016, star_num 2568, country_num 128, mode ics \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d63240c34650>:26: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(self.user_embed.weight)\n",
            "<ipython-input-3-d63240c34650>:27: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(self.item_embed.weight)\n",
            "<ipython-input-3-d63240c34650>:31: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(self.user_bias.weight, 0)\n",
            "<ipython-input-3-d63240c34650>:32: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(self.item_bias.weight, 0)\n",
            "<ipython-input-3-d63240c34650>:20: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(m.weight)\n",
            "<ipython-input-3-d63240c34650>:22: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(m.bias, 0)\n",
            "<ipython-input-2-58aca4851266>:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(m.weight)\n",
            "<ipython-input-2-58aca4851266>:16: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(m.bias, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##################################################\n",
            "epoch:  0       tensor(0.4547, device='cuda:0')\n",
            "time =  25.63979172706604\n",
            "test rmse,mse,mae:  1.0551795103140864 1.1134037989866754 0.8650801264458984\n",
            "##################################################\n",
            "epoch:  1       tensor(0.6400, device='cuda:0')\n",
            "time =  25.227171182632446\n",
            "test rmse,mse,mae:  1.0375909193411104 1.0765949158991308 0.8425302760576113\n",
            "##################################################\n",
            "epoch:  2       tensor(0.5679, device='cuda:0')\n",
            "time =  26.013632774353027\n",
            "test rmse,mse,mae:  1.0407498787481817 1.083160310114355 0.8477820615290809\n",
            "##################################################\n",
            "epoch:  3       tensor(0.5838, device='cuda:0')\n",
            "time =  26.210723400115967\n",
            "test rmse,mse,mae:  1.033925381668952 1.069001694859288 0.8414785545739618\n",
            "##################################################\n",
            "epoch:  4       tensor(0.4834, device='cuda:0')\n",
            "time =  25.66456913948059\n",
            "test rmse,mse,mae:  1.024149763025222 1.0488827371046185 0.8267105110936855\n",
            "##################################################\n",
            "epoch:  5       tensor(0.5316, device='cuda:0')\n",
            "time =  25.752330780029297\n",
            "test rmse,mse,mae:  1.0312214570858862 1.0634176935543382 0.8386450423732458\n",
            "##################################################\n",
            "epoch:  6       tensor(0.5572, device='cuda:0')\n",
            "time =  26.31606960296631\n",
            "test rmse,mse,mae:  1.0370669387797258 1.0755078355099517 0.8449984523708111\n",
            "##################################################\n",
            "epoch:  7       tensor(0.4664, device='cuda:0')\n",
            "time =  25.64439558982849\n",
            "test rmse,mse,mae:  1.017280876401514 1.0348603814922326 0.8226738845245748\n",
            "##################################################\n",
            "epoch:  8       tensor(0.6424, device='cuda:0')\n",
            "time =  25.642802476882935\n",
            "test rmse,mse,mae:  1.0279068395520345 1.056592470797852 0.8334566816498962\n",
            "##################################################\n",
            "epoch:  9       tensor(0.5776, device='cuda:0')\n",
            "time =  25.70203924179077\n",
            "test rmse,mse,mae:  1.0342058196918982 1.069581677484591 0.8421473879438871\n",
            "##################################################\n",
            "epoch:  10       tensor(0.4423, device='cuda:0')\n",
            "time =  26.457378387451172\n",
            "test rmse,mse,mae:  1.0338978458853438 1.068944755726354 0.8386223624549072\n",
            "##################################################\n",
            "epoch:  11       tensor(0.4730, device='cuda:0')\n",
            "time =  26.61316728591919\n",
            "test rmse,mse,mae:  1.02944934146147 1.0597659466354545 0.8323795413078682\n",
            "##################################################\n",
            "epoch:  12       tensor(0.5119, device='cuda:0')\n",
            "time =  26.652315378189087\n",
            "test rmse,mse,mae:  1.0354563512355777 1.0721698553140961 0.8393934981535606\n",
            "##################################################\n",
            "epoch:  13       tensor(0.4603, device='cuda:0')\n",
            "time =  26.759870767593384\n",
            "test rmse,mse,mae:  1.0145313048269138 1.0292737684738 0.8145589905121068\n",
            "##################################################\n",
            "epoch:  14       tensor(0.5066, device='cuda:0')\n",
            "time =  26.056867599487305\n",
            "test rmse,mse,mae:  1.0585622290640306 1.120553992801009 0.8625776220562043\n",
            "##################################################\n",
            "epoch:  15       tensor(0.5133, device='cuda:0')\n",
            "time =  26.35854697227478\n",
            "test rmse,mse,mae:  1.0665346907656685 1.13749624660662 0.8675198606954018\n",
            "##################################################\n",
            "epoch:  16       tensor(0.4680, device='cuda:0')\n",
            "time =  26.58083152770996\n",
            "test rmse,mse,mae:  1.0505375753233814 1.1036291971663295 0.8522519877407009\n",
            "##################################################\n",
            "epoch:  17       tensor(0.4861, device='cuda:0')\n",
            "time =  26.53115725517273\n",
            "test rmse,mse,mae:  1.0524122100393976 1.1075714598400093 0.8555114888856223\n",
            "##################################################\n",
            "epoch:  18       tensor(0.5014, device='cuda:0')\n",
            "time =  25.779537200927734\n",
            "test rmse,mse,mae:  1.0450640546031345 1.092158878223543 0.8434302464906632\n",
            "##################################################\n",
            "epoch:  19       tensor(0.4137, device='cuda:0')\n",
            "time =  25.685675621032715\n",
            "test rmse,mse,mae:  1.053331372820243 1.1095069809673774 0.8512558478868197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## user cold start train loop"
      ],
      "metadata": {
        "id": "6UWW2cRkLzP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def user_cold_start_train_loop():\n",
        "    #item cold start\n",
        "    \"\"\"\n",
        "    f_info = '../ml100k/uiinfo.pkl'\n",
        "    f_neighbor = '../ml100k/neighbor_aspect_extension_2_zscore_ics_uuii_0.20.pkl'\n",
        "    f_train = '../ml100k/ics_train.dat'\n",
        "    f_test = '../ml100k/ics_val.dat'\n",
        "    f_model = '../ml100k/agnn_ics_'\n",
        "    \"\"\"\n",
        "\n",
        "    # user cold start\n",
        "    f_info = '../ml100k/uiinfo.pkl'\n",
        "    f_neighbor = '../ml100k/neighbor_aspect_extension_2_zscore_ucs_uuii.pkl'\n",
        "    f_train = '../ml100k/ucs_train.dat'\n",
        "    f_test = '../ml100k/ucs_val.dat'\n",
        "    f_model = '../ml100k/agnn_ucs_'\n",
        "\n",
        "\n",
        "    \"\"\"# warm start\n",
        "    f_info = '../ml100k/uiinfo.pkl'\n",
        "    f_neighbor = '../ml100k/neighbor_aspect_extension_2_zscore_warm_uuii.pkl'\n",
        "    f_train = '../ml100k/warm_train.dat'\n",
        "    f_test = '../ml100k/warm_val.dat'\n",
        "    f_model = '../ml100k/agnn_warm_'\n",
        "    mode = 'warm'\"\"\"\n",
        "\n",
        "    # use best hyperparameters from paper\n",
        "    # see section 4.1.4 and 4.3 for description of how they got them\n",
        "\n",
        "    print(\"\\nParameters:\")\n",
        "    print(FLAGS)\n",
        "\n",
        "    with open(f_neighbor, 'rb') as f:\n",
        "        neighbor_dict = pickle.load(f)\n",
        "    user_nei_dict = neighbor_dict['user_nei_dict']\n",
        "    item_nei_dict = neighbor_dict['item_nei_dict']\n",
        "    director_num = neighbor_dict['director_num']\n",
        "    writer_num = neighbor_dict['writer_num']\n",
        "    star_num = neighbor_dict['star_num']\n",
        "    country_num = neighbor_dict['country_num']\n",
        "\n",
        "    item_director_dict = neighbor_dict['item_director_dict']    #dict[i]=[x,x,x]\n",
        "    item_writer_dict = neighbor_dict['item_writer_dict']        #dict[i]=[x,x,x]\n",
        "    item_star_dict = neighbor_dict['item_star_dict']            #dict[i]=[x,x,x]\n",
        "    item_country_dict = neighbor_dict['item_country_dict']      #dict[i]=[x,x,x,x,x,x,x,x]\n",
        "\n",
        "    with open(f_info, 'rb') as f:\n",
        "        item_info = pickle.load(f)\n",
        "    user_num = item_info['user_num']\n",
        "    item_num = item_info['item_num']\n",
        "    gender_num = item_info['gender_num']\n",
        "    age_num = item_info['age_num']\n",
        "    occupation_num = item_info['occupation_num']\n",
        "    genre_num = item_info['genre_num']\n",
        "    user_feature_dict = item_info['user_feature_dict']  #gender, age, occupation    dict[u]=[x,x,x]\n",
        "    item_feature_dict = item_info['item_feature_dict']  #genre                      dict[i]=[x,x,x,x,x,x]\n",
        "\n",
        "    print(\"user_num {}, item_num {}, gender_num {}, age_num {}, occupation_num {}, genre_num {}, director_num {}, writer_num {}, star_num {}, country_num {}, mode {} \".format(user_num, item_num, gender_num, age_num, occupation_num, genre_num, director_num, writer_num, star_num, country_num, mode))\n",
        "\n",
        "    train_steps, train_list = get_data_list(f_train, batch_size=FLAGS.batch_size)\n",
        "    test_steps, test_list = get_data_list(f_test, batch_size=FLAGS.batch_size)\n",
        "\n",
        "    model = AGNN(user_num, item_num, gender_num, age_num, occupation_num, genre_num, director_num, writer_num, star_num, country_num, FLAGS.embed_size, FLAGS.attention_size, FLAGS.dropout)\n",
        "    model.cuda()\n",
        "\n",
        "    loss_function = torch.nn.MSELoss(size_average=False)\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=FLAGS.lr, weight_decay=0.001)\n",
        "\n",
        "    writer = SummaryWriter()  # For visualization\n",
        "    #f_loss_curve = open('tmp_loss_curve.txt', 'w')\n",
        "    best_rmse = 5\n",
        "\n",
        "    count = 0\n",
        "    for epoch in range(FLAGS.epochs):\n",
        "        #tmp_main_loss, tmp_vae_loss = [], []\n",
        "        model.train()  # Enable dropout (if have).\n",
        "        start_time = time.time()\n",
        "        train_dataloader = get_batch_instances(train_list, user_feature_dict, item_feature_dict, item_director_dict, item_writer_dict, item_star_dict, item_country_dict,  batch_size=FLAGS.batch_size, user_nei_dict=user_nei_dict, item_nei_dict=item_nei_dict, shuffle=True)\n",
        "\n",
        "        for idx, batch_data in enumerate(train_dataloader): #u, i, l, u_self_cate, u_onehop_id, u_onehop_rating, u_onehop_cate, i_self_cate, i_onehop_id, i_onehop_cate\n",
        "            user = torch.LongTensor(batch_data[0]).cuda()\n",
        "            item = torch.LongTensor(batch_data[1]).cuda()\n",
        "            label = torch.FloatTensor(batch_data[2]).cuda()\n",
        "            user_self_cate = torch.LongTensor(batch_data[3]).cuda()\n",
        "            user_onehop_id = torch.LongTensor(batch_data[4]).cuda()\n",
        "            user_onehop_cate = torch.LongTensor(batch_data[5]).cuda()\n",
        "            item_self_cate, item_self_director, item_self_writer, item_self_star, item_self_country = torch.LongTensor(batch_data[6])[:, 0:6].cuda(), torch.LongTensor(batch_data[6])[:, 6:9].cuda(), torch.LongTensor(batch_data[6])[:, 9:12].cuda(), torch.LongTensor(batch_data[6])[:, 12:15].cuda(), torch.LongTensor(batch_data[6])[:, 15:].cuda()\n",
        "            item_onehop_id = torch.LongTensor(batch_data[7]).cuda()\n",
        "            item_onehop_cate, item_onehop_director, item_onehop_writer, item_onehop_star, item_onehop_country = torch.LongTensor(batch_data[8])[:, :, 0:6].cuda(), torch.LongTensor(batch_data[8])[:, :, 6:9].cuda(), torch.LongTensor(batch_data[8])[:, :, 9:12].cuda(), torch.LongTensor(batch_data[8])[:, :, 12:15].cuda(), torch.LongTensor(batch_data[8])[:, :, 15:].cuda()\n",
        "\n",
        "            model.zero_grad()\n",
        "            prediction, recon_loss, kl_loss = model(user, item, user_self_cate, user_onehop_id, user_onehop_cate, item_self_cate, item_self_director, item_self_writer, item_self_star, item_self_country, item_onehop_id, item_onehop_cate, item_onehop_director, item_onehop_writer, item_onehop_star, item_onehop_country, mode='train')\n",
        "\n",
        "            label = Variable(label)\n",
        "\n",
        "            main_loss = loss_function(prediction, label)\n",
        "            loss = main_loss + FLAGS.vae_lambda * (recon_loss + kl_loss)\n",
        "\n",
        "            loss.backward()\n",
        "            # nn.utils.clip_grad_norm(model.parameters(), FLAGS.clip_norm)\n",
        "            optimizer.step()\n",
        "            writer.add_scalar('data/loss', loss.data, count)\n",
        "            count += 1\n",
        "\n",
        "        tmploss = torch.sqrt(loss / FLAGS.batch_size)\n",
        "        print(50 * '#')\n",
        "        print('epoch: ', epoch, '     ', tmploss.detach())\n",
        "\n",
        "        model.eval()\n",
        "        print('time = ', time.time() - start_time)\n",
        "        test_dataloader = get_batch_instances(test_list, user_feature_dict, item_feature_dict, item_director_dict, item_writer_dict, item_star_dict, item_country_dict, batch_size=FLAGS.batch_size, user_nei_dict=user_nei_dict, item_nei_dict=item_nei_dict, shuffle=False)\n",
        "        rmse, mse, mae, label_lst, pred_lst = metrics(model, test_dataloader)\n",
        "        print('test rmse,mse,mae: ', rmse,mse,mae)\n",
        "\n",
        "        \"\"\"if (rmse < best_rmse):\n",
        "            best_rmse = rmse\n",
        "            f_name = f_model + str(best_rmse)[:7] + '.dat' #f_model + str(best_rmse)[:7] + '.dat'\n",
        "            #torch.save(model, f_name)\n",
        "            f = open(f_name, 'w')\n",
        "            res_dict = {}\n",
        "            res_dict['label'] = label_lst\n",
        "            res_dict['pred'] = pred_lst\n",
        "            json.dump(res_dict, f)\n",
        "            f.close()\n",
        "            print('save result ok')\"\"\""
      ],
      "metadata": {
        "id": "eMO3fISXFqxs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## user cold start evaluation"
      ],
      "metadata": {
        "id": "k6QEU4ZGMV5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mode = 'ucs'\n",
        "user_cold_start_train_loop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdlNfOzKJtmV",
        "outputId": "02b3d603-40f8-4593-c99b-558a4c481e35"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Parameters:\n",
            "<__main__.Flags object at 0x7a89dedb2230>\n",
            "user_num 944, item_num 1683, gender_num 2, age_num 7, occupation_num 21, genre_num 19, director_num 1112, writer_num 2016, star_num 2568, country_num 128, mode ucs \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d63240c34650>:26: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(self.user_embed.weight)\n",
            "<ipython-input-3-d63240c34650>:27: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(self.item_embed.weight)\n",
            "<ipython-input-3-d63240c34650>:31: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(self.user_bias.weight, 0)\n",
            "<ipython-input-3-d63240c34650>:32: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(self.item_bias.weight, 0)\n",
            "<ipython-input-3-d63240c34650>:20: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(m.weight)\n",
            "<ipython-input-3-d63240c34650>:22: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(m.bias, 0)\n",
            "<ipython-input-2-58aca4851266>:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(m.weight)\n",
            "<ipython-input-2-58aca4851266>:16: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(m.bias, 0)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##################################################\n",
            "epoch:  0       tensor(0.7474, device='cuda:0')\n",
            "time =  24.88870096206665\n",
            "test rmse,mse,mae:  1.049969338678701 1.1024356121653887 0.8612345195237062\n",
            "##################################################\n",
            "epoch:  1       tensor(0.6623, device='cuda:0')\n",
            "time =  35.81278944015503\n",
            "test rmse,mse,mae:  1.0392137655514728 1.0799652505116717 0.8486152374263131\n",
            "##################################################\n",
            "epoch:  2       tensor(0.6642, device='cuda:0')\n",
            "time =  29.36483907699585\n",
            "test rmse,mse,mae:  1.0311658194312443 1.0633029471633095 0.837472306369073\n",
            "##################################################\n",
            "epoch:  3       tensor(0.6220, device='cuda:0')\n",
            "time =  24.726237058639526\n",
            "test rmse,mse,mae:  1.0244357870825735 1.049468681855492 0.8253190897241172\n",
            "##################################################\n",
            "epoch:  4       tensor(0.5760, device='cuda:0')\n",
            "time =  25.80716300010681\n",
            "test rmse,mse,mae:  1.0209713729027456 1.0423825442869172 0.8211119273299292\n",
            "##################################################\n",
            "epoch:  5       tensor(0.6745, device='cuda:0')\n",
            "time =  24.82118821144104\n",
            "test rmse,mse,mae:  1.0304993106229683 1.0619288291944127 0.8366071620152202\n",
            "##################################################\n",
            "epoch:  6       tensor(0.6178, device='cuda:0')\n",
            "time =  24.739502906799316\n",
            "test rmse,mse,mae:  1.0363316815093775 1.0739833541000539 0.8438857141148272\n",
            "##################################################\n",
            "epoch:  7       tensor(0.5900, device='cuda:0')\n",
            "time =  26.005868673324585\n",
            "test rmse,mse,mae:  1.0524615476608592 1.1076753093046912 0.8639951905257638\n",
            "##################################################\n",
            "epoch:  8       tensor(0.6467, device='cuda:0')\n",
            "time =  24.756019353866577\n",
            "test rmse,mse,mae:  1.0442566827658657 1.09047201950117 0.8535394265017751\n",
            "##################################################\n",
            "epoch:  9       tensor(0.6376, device='cuda:0')\n",
            "time =  24.837549686431885\n",
            "test rmse,mse,mae:  1.0362461629071784 1.0738061101398506 0.8393437034771138\n",
            "##################################################\n",
            "epoch:  10       tensor(0.7189, device='cuda:0')\n",
            "time =  24.765028953552246\n",
            "test rmse,mse,mae:  1.0465779287732178 1.0953253609952383 0.8528497852806748\n",
            "##################################################\n",
            "epoch:  11       tensor(0.6223, device='cuda:0')\n",
            "time =  24.872690677642822\n",
            "test rmse,mse,mae:  1.0344974194547822 1.0701849108586035 0.8377579596035336\n",
            "##################################################\n",
            "epoch:  12       tensor(0.6051, device='cuda:0')\n",
            "time =  24.815537452697754\n",
            "test rmse,mse,mae:  1.0561035015913605 1.1153546060735327 0.8626223661771804\n",
            "##################################################\n",
            "epoch:  13       tensor(0.6307, device='cuda:0')\n",
            "time =  24.7042236328125\n",
            "test rmse,mse,mae:  1.057805553993483 1.1189525900594592 0.863504116316147\n",
            "##################################################\n",
            "epoch:  14       tensor(0.5932, device='cuda:0')\n",
            "time =  24.723745822906494\n",
            "test rmse,mse,mae:  1.0435387622640644 1.0889731483476153 0.847848774803824\n",
            "##################################################\n",
            "epoch:  15       tensor(0.6341, device='cuda:0')\n",
            "time =  25.212082386016846\n",
            "test rmse,mse,mae:  1.0471272975124564 1.0964755771957402 0.8513055432672746\n",
            "##################################################\n",
            "epoch:  16       tensor(0.6232, device='cuda:0')\n",
            "time =  30.76826763153076\n",
            "test rmse,mse,mae:  1.0556863545491102 1.1144736791811896 0.8641612683928048\n",
            "##################################################\n",
            "epoch:  17       tensor(0.5275, device='cuda:0')\n",
            "time =  28.602800846099854\n",
            "test rmse,mse,mae:  1.0341164422106208 1.0693968160503524 0.8331486158431668\n",
            "##################################################\n",
            "epoch:  18       tensor(0.5671, device='cuda:0')\n",
            "time =  31.11536955833435\n",
            "test rmse,mse,mae:  1.0671848083138042 1.1388834150957712 0.8746063546745665\n",
            "##################################################\n",
            "epoch:  19       tensor(0.6861, device='cuda:0')\n",
            "time =  25.177409648895264\n",
            "test rmse,mse,mae:  1.058552710943469 1.120533841845767 0.8654094692894271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## warm start train loop"
      ],
      "metadata": {
        "id": "UVyxE7gxLtHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def warm_start_train_loop():\n",
        "    #item cold start\n",
        "    \"\"\"\n",
        "    f_info = '../ml100k/uiinfo.pkl'\n",
        "    f_neighbor = '../ml100k/neighbor_aspect_extension_2_zscore_ics_uuii_0.20.pkl'\n",
        "    f_train = '../ml100k/ics_train.dat'\n",
        "    f_test = '../ml100k/ics_val.dat'\n",
        "    f_model = '../ml100k/agnn_ics_'\n",
        "\n",
        "    # user cold start\n",
        "    f_info = '../ml100k/uiinfo.pkl'\n",
        "    f_neighbor = '../ml100k/neighbor_aspect_extension_2_zscore_ucs_uuii.pkl'\n",
        "    f_train = '../ml100k/ucs_train.dat'\n",
        "    f_test = '../ml100k/ucs_val.dat'\n",
        "    f_model = '../ml100k/agnn_ucs_'\n",
        "    \"\"\"\n",
        "\n",
        "    # warm start\n",
        "    f_info = '../ml100k/uiinfo.pkl'\n",
        "    f_neighbor = '../ml100k/neighbor_aspect_extension_2_zscore_warm_uuii.pkl'\n",
        "    f_train = '../ml100k/warm_train.dat'\n",
        "    f_test = '../ml100k/warm_val.dat'\n",
        "    f_model = '../ml100k/agnn_warm_'\n",
        "\n",
        "    # use best hyperparameters from paper\n",
        "    # see section 4.1.4 and 4.3 for description of how they got them\n",
        "\n",
        "    print(\"\\nParameters:\")\n",
        "    print(FLAGS)\n",
        "\n",
        "    with open(f_neighbor, 'rb') as f:\n",
        "        neighbor_dict = pickle.load(f)\n",
        "    user_nei_dict = neighbor_dict['user_nei_dict']\n",
        "    item_nei_dict = neighbor_dict['item_nei_dict']\n",
        "    director_num = neighbor_dict['director_num']\n",
        "    writer_num = neighbor_dict['writer_num']\n",
        "    star_num = neighbor_dict['star_num']\n",
        "    country_num = neighbor_dict['country_num']\n",
        "\n",
        "    item_director_dict = neighbor_dict['item_director_dict']    #dict[i]=[x,x,x]\n",
        "    item_writer_dict = neighbor_dict['item_writer_dict']        #dict[i]=[x,x,x]\n",
        "    item_star_dict = neighbor_dict['item_star_dict']            #dict[i]=[x,x,x]\n",
        "    item_country_dict = neighbor_dict['item_country_dict']      #dict[i]=[x,x,x,x,x,x,x,x]\n",
        "\n",
        "    with open(f_info, 'rb') as f:\n",
        "        item_info = pickle.load(f)\n",
        "    user_num = item_info['user_num']\n",
        "    item_num = item_info['item_num']\n",
        "    gender_num = item_info['gender_num']\n",
        "    age_num = item_info['age_num']\n",
        "    occupation_num = item_info['occupation_num']\n",
        "    genre_num = item_info['genre_num']\n",
        "    user_feature_dict = item_info['user_feature_dict']  #gender, age, occupation    dict[u]=[x,x,x]\n",
        "    item_feature_dict = item_info['item_feature_dict']  #genre                      dict[i]=[x,x,x,x,x,x]\n",
        "\n",
        "    print(\"user_num {}, item_num {}, gender_num {}, age_num {}, occupation_num {}, genre_num {}, director_num {}, writer_num {}, star_num {}, country_num {}, mode {} \".format(user_num, item_num, gender_num, age_num, occupation_num, genre_num, director_num, writer_num, star_num, country_num, mode))\n",
        "\n",
        "    train_steps, train_list = get_data_list(f_train, batch_size=FLAGS.batch_size)\n",
        "    test_steps, test_list = get_data_list(f_test, batch_size=FLAGS.batch_size)\n",
        "\n",
        "    model = AGNN(user_num, item_num, gender_num, age_num, occupation_num, genre_num, director_num, writer_num, star_num, country_num, FLAGS.embed_size, FLAGS.attention_size, FLAGS.dropout)\n",
        "    model.cuda()\n",
        "\n",
        "    loss_function = torch.nn.MSELoss(size_average=False)\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=FLAGS.lr, weight_decay=0.001)\n",
        "\n",
        "    writer = SummaryWriter()  # For visualization\n",
        "    #f_loss_curve = open('tmp_loss_curve.txt', 'w')\n",
        "    best_rmse = 5\n",
        "\n",
        "    count = 0\n",
        "    for epoch in range(FLAGS.epochs):\n",
        "        #tmp_main_loss, tmp_vae_loss = [], []\n",
        "        model.train()  # Enable dropout (if have).\n",
        "        start_time = time.time()\n",
        "        train_dataloader = get_batch_instances(train_list, user_feature_dict, item_feature_dict, item_director_dict, item_writer_dict, item_star_dict, item_country_dict,  batch_size=FLAGS.batch_size, user_nei_dict=user_nei_dict, item_nei_dict=item_nei_dict, shuffle=True)\n",
        "\n",
        "        for idx, batch_data in enumerate(train_dataloader): #u, i, l, u_self_cate, u_onehop_id, u_onehop_rating, u_onehop_cate, i_self_cate, i_onehop_id, i_onehop_cate\n",
        "            user = torch.LongTensor(batch_data[0]).cuda()\n",
        "            item = torch.LongTensor(batch_data[1]).cuda()\n",
        "            label = torch.FloatTensor(batch_data[2]).cuda()\n",
        "            user_self_cate = torch.LongTensor(batch_data[3]).cuda()\n",
        "            user_onehop_id = torch.LongTensor(batch_data[4]).cuda()\n",
        "            user_onehop_cate = torch.LongTensor(batch_data[5]).cuda()\n",
        "            item_self_cate, item_self_director, item_self_writer, item_self_star, item_self_country = torch.LongTensor(batch_data[6])[:, 0:6].cuda(), torch.LongTensor(batch_data[6])[:, 6:9].cuda(), torch.LongTensor(batch_data[6])[:, 9:12].cuda(), torch.LongTensor(batch_data[6])[:, 12:15].cuda(), torch.LongTensor(batch_data[6])[:, 15:].cuda()\n",
        "            item_onehop_id = torch.LongTensor(batch_data[7]).cuda()\n",
        "            item_onehop_cate, item_onehop_director, item_onehop_writer, item_onehop_star, item_onehop_country = torch.LongTensor(batch_data[8])[:, :, 0:6].cuda(), torch.LongTensor(batch_data[8])[:, :, 6:9].cuda(), torch.LongTensor(batch_data[8])[:, :, 9:12].cuda(), torch.LongTensor(batch_data[8])[:, :, 12:15].cuda(), torch.LongTensor(batch_data[8])[:, :, 15:].cuda()\n",
        "\n",
        "            model.zero_grad()\n",
        "            prediction, recon_loss, kl_loss = model(user, item, user_self_cate, user_onehop_id, user_onehop_cate, item_self_cate, item_self_director, item_self_writer, item_self_star, item_self_country, item_onehop_id, item_onehop_cate, item_onehop_director, item_onehop_writer, item_onehop_star, item_onehop_country, mode='train')\n",
        "\n",
        "            label = Variable(label)\n",
        "\n",
        "            main_loss = loss_function(prediction, label)\n",
        "            loss = main_loss + FLAGS.vae_lambda * (recon_loss + kl_loss)\n",
        "\n",
        "            loss.backward()\n",
        "            # nn.utils.clip_grad_norm(model.parameters(), FLAGS.clip_norm)\n",
        "            optimizer.step()\n",
        "            writer.add_scalar('data/loss', loss.data, count)\n",
        "            count += 1\n",
        "\n",
        "        tmploss = torch.sqrt(loss / FLAGS.batch_size)\n",
        "        print(50 * '#')\n",
        "        print('epoch: ', epoch, '     ', tmploss.detach())\n",
        "\n",
        "        model.eval()\n",
        "        print('time = ', time.time() - start_time)\n",
        "        test_dataloader = get_batch_instances(test_list, user_feature_dict, item_feature_dict, item_director_dict, item_writer_dict, item_star_dict, item_country_dict, batch_size=FLAGS.batch_size, user_nei_dict=user_nei_dict, item_nei_dict=item_nei_dict, shuffle=False)\n",
        "        rmse, mse, mae, label_lst, pred_lst = metrics(model, test_dataloader)\n",
        "        print('test rmse,mse,mae: ', rmse,mse,mae)\n",
        "\n",
        "        \"\"\"if (rmse < best_rmse):\n",
        "            best_rmse = rmse\n",
        "            f_name = f_model + str(best_rmse)[:7] + '.dat' #f_model + str(best_rmse)[:7] + '.dat'\n",
        "            #torch.save(model, f_name)\n",
        "            f = open(f_name, 'w')\n",
        "            res_dict = {}\n",
        "            res_dict['label'] = label_lst\n",
        "            res_dict['pred'] = pred_lst\n",
        "            json.dump(res_dict, f)\n",
        "            f.close()\n",
        "            print('save result ok')\"\"\""
      ],
      "metadata": {
        "id": "XqoePc5pJxmo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## warm start evaluation"
      ],
      "metadata": {
        "id": "4CiwBBPhMa3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mode = 'warm'\n",
        "warm_start_train_loop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMdmbeMwKDI_",
        "outputId": "8cc65952-5d35-43ff-f96a-3262fa545c89"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Parameters:\n",
            "<__main__.Flags object at 0x7a89dedb2230>\n",
            "user_num 944, item_num 1683, gender_num 2, age_num 7, occupation_num 21, genre_num 19, director_num 1112, writer_num 2016, star_num 2568, country_num 128, mode warm \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d63240c34650>:26: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(self.user_embed.weight)\n",
            "<ipython-input-3-d63240c34650>:27: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(self.item_embed.weight)\n",
            "<ipython-input-3-d63240c34650>:31: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(self.user_bias.weight, 0)\n",
            "<ipython-input-3-d63240c34650>:32: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(self.item_bias.weight, 0)\n",
            "<ipython-input-3-d63240c34650>:20: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(m.weight)\n",
            "<ipython-input-3-d63240c34650>:22: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(m.bias, 0)\n",
            "<ipython-input-2-58aca4851266>:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(m.weight)\n",
            "<ipython-input-2-58aca4851266>:16: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(m.bias, 0)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##################################################\n",
            "epoch:  0       tensor(1.0151, device='cuda:0')\n",
            "time =  23.46168541908264\n",
            "test rmse,mse,mae:  0.9589199948953548 0.9195275566101074 0.763196667766571\n",
            "##################################################\n",
            "epoch:  1       tensor(1.0216, device='cuda:0')\n",
            "time =  22.789565086364746\n",
            "test rmse,mse,mae:  0.9589669293279343 0.9196175715446472 0.7543844308853149\n",
            "##################################################\n",
            "epoch:  2       tensor(0.9419, device='cuda:0')\n",
            "time =  23.35577702522278\n",
            "test rmse,mse,mae:  0.949622653104155 0.9017831832885742 0.7553976072311401\n",
            "##################################################\n",
            "epoch:  3       tensor(1.0448, device='cuda:0')\n",
            "time =  24.511520862579346\n",
            "test rmse,mse,mae:  0.9470426108694202 0.8968897068023681 0.7575070610046387\n",
            "##################################################\n",
            "epoch:  4       tensor(0.8948, device='cuda:0')\n",
            "time =  24.16345715522766\n",
            "test rmse,mse,mae:  0.934200380166723 0.8727303503036499 0.7364975538253784\n",
            "##################################################\n",
            "epoch:  5       tensor(0.9354, device='cuda:0')\n",
            "time =  25.112201929092407\n",
            "test rmse,mse,mae:  0.9285053642582248 0.8621222114562989 0.7352402606964111\n",
            "##################################################\n",
            "epoch:  6       tensor(0.9805, device='cuda:0')\n",
            "time =  25.25800395011902\n",
            "test rmse,mse,mae:  0.9221713189231148 0.850399941444397 0.7257570743560791\n",
            "##################################################\n",
            "epoch:  7       tensor(0.9544, device='cuda:0')\n",
            "time =  24.777125358581543\n",
            "test rmse,mse,mae:  0.920686271788371 0.8476632110595703 0.7303611227989196\n",
            "##################################################\n",
            "epoch:  8       tensor(0.9767, device='cuda:0')\n",
            "time =  24.588475227355957\n",
            "test rmse,mse,mae:  0.9142788042846183 0.8359057319641113 0.7215058358192444\n",
            "##################################################\n",
            "epoch:  9       tensor(0.9493, device='cuda:0')\n",
            "time =  23.678335428237915\n",
            "test rmse,mse,mae:  0.9147333928237776 0.8367371799468994 0.7168823422431946\n",
            "##################################################\n",
            "epoch:  10       tensor(0.8684, device='cuda:0')\n",
            "time =  23.609070777893066\n",
            "test rmse,mse,mae:  0.9147438462043356 0.8367563041687012 0.7192187965393066\n",
            "##################################################\n",
            "epoch:  11       tensor(0.8438, device='cuda:0')\n",
            "time =  22.662477731704712\n",
            "test rmse,mse,mae:  0.9159389591368106 0.838944176864624 0.7179137512207031\n",
            "##################################################\n",
            "epoch:  12       tensor(0.8257, device='cuda:0')\n",
            "time =  23.552730083465576\n",
            "test rmse,mse,mae:  0.9248727844496338 0.855389667415619 0.719288480758667\n",
            "##################################################\n",
            "epoch:  13       tensor(0.9102, device='cuda:0')\n",
            "time =  23.57943606376648\n",
            "test rmse,mse,mae:  0.9224311471070669 0.8508792211532593 0.7220914805412293\n",
            "##################################################\n",
            "epoch:  14       tensor(0.8869, device='cuda:0')\n",
            "time =  23.601294994354248\n",
            "test rmse,mse,mae:  0.926993960555319 0.8593178029060364 0.7239862546920777\n",
            "##################################################\n",
            "epoch:  15       tensor(0.7820, device='cuda:0')\n",
            "time =  23.78800344467163\n",
            "test rmse,mse,mae:  0.9317480850527579 0.8681544939994812 0.7236331289291382\n",
            "##################################################\n",
            "epoch:  16       tensor(0.8608, device='cuda:0')\n",
            "time =  23.780677556991577\n",
            "test rmse,mse,mae:  0.9322286120411585 0.8690501851081848 0.7308153141021728\n",
            "##################################################\n",
            "epoch:  17       tensor(0.9712, device='cuda:0')\n",
            "time =  23.22764825820923\n",
            "test rmse,mse,mae:  0.9345332666785761 0.8733524265289306 0.7332608875274658\n",
            "##################################################\n",
            "epoch:  18       tensor(0.8663, device='cuda:0')\n",
            "time =  25.50348711013794\n",
            "test rmse,mse,mae:  0.9415520330101138 0.8865202308654785 0.7314580081939698\n",
            "##################################################\n",
            "epoch:  19       tensor(0.8605, device='cuda:0')\n",
            "time =  23.601751565933228\n",
            "test rmse,mse,mae:  0.9423528318579476 0.8880288597106933 0.7393002979278565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sv9y2PysMfuf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}